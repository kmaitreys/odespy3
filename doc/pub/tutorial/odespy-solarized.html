<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="description" content="A Tutorial for the Odespy Interface to ODE Solvers">

<title>A Tutorial for the Odespy Interface to ODE Solvers</title>


<link href="https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_styles/style_solarized_box/css/solarized_light_code.css" rel="stylesheet" type="text/css" title="light"/>
<script src="https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_styles/style_solarized_box/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<link href="http://thomasf.github.io/solarized-css/solarized-light.min.css" rel="stylesheet">
<style type="text/css">
h1 {color: #b58900;}  /* yellow */
/* h1 {color: #cb4b16;}  orange */
/* h1 {color: #d33682;}  magenta, the original choice of thomasf */
code { padding: 0px; background-color: inherit; }
pre {
  border: 0pt solid #93a1a1;
  box-shadow: none;
}
.alert-text-small   { font-size: 80%;  }
.alert-text-large   { font-size: 130%; }
.alert-text-normal  { font-size: 90%;  }
.alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:1px solid #93a1a1;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  -moz-border-radius: 4px;
  color: #555;
  background-color: #eee8d5;
  background-position: 10px 5px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 55px;
  width: 75%;
 }
.alert-block {padding-top:14px; padding-bottom:14px}
.alert-block > p, .alert-block > ul {margin-bottom:1em}
.alert li {margin-top: 1em}
.alert-block p+p {margin-top:5px}
.alert-notice { background-image: url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_yellow_notice.png); }
.alert-summary  { background-image:url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_yellow_summary.png); }
.alert-warning { background-image: url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_yellow_warning.png); }
.alert-question {background-image:url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_yellow_question.png); }

div { text-align: justify; text-justify: inter-word; }
</style>


</head>

<!-- tocinfo
{'highest level': 1,
 'sections': [(' Motivation ', 1, 'ode:sec:motivation', 'ode:sec:motivation'),
              (' Traditional Approach ', 2, None, '___sec1'),
              (' LSODE ', 3, None, '___sec2'),
              (' MATLAB ', 3, None, '___sec3'),
              (' Python ', 3, None, '___sec4'),
              (" Odespy's Unified Interface ", 2, None, '___sec5'),
              (' Methods and Implementations Offered by Odespy ',
               2,
               None,
               '___sec6'),
              (' Installation ', 1, None, '___sec7'),
              (' Basic Usage ', 1, None, '___sec8'),
              (' Overview ', 2, None, '___sec9'),
              (' Step 1 ', 3, None, '___sec10'),
              (' Step 2 ', 3, None, '___sec11'),
              (' Step 3 ', 3, None, '___sec12'),
              (' Step 4 ', 3, None, '___sec13'),
              (' Step 5 ', 3, None, '___sec14'),
              (' Step 6 ', 3, None, '___sec15'),
              (' First Example: Logistic Growth ',
               2,
               'ode:sec:exgr',
               'ode:sec:exgr'),
              (' Parameters in the Right-Hand Side Function ',
               2,
               'ode:sec:exgr:farg',
               'ode:sec:exgr:farg'),
              (' Continuing a Previous Simulation ', 2, None, '___sec18'),
              (' Termination Criterion for the Simulation ',
               2,
               None,
               '___sec19'),
              (' A Class-Based Implementation ', 2, None, '___sec20'),
              (' Using Other Symbols ', 2, None, '___sec21'),
              (' Example: Solving an ODE System ',
               2,
               'ode:sec:ex:osc',
               'ode:sec:ex:osc'),
              (' The Euler-Cromer Method ', 2, None, '___sec23'),
              (' Testing Several Methods ', 2, None, '___sec24'),
              (' More Advanced Implementations ', 1, None, '___sec25'),
              (' Make a Subclass of Class Problem ', 2, None, '___sec26'),
              (' Example: Solving a Complex ODE Problem ',
               2,
               None,
               '___sec27'),
              (' Quick Implementation ', 3, None, '___sec28'),
              (' Comparison of Methods ', 3, None, '___sec29'),
              (' Avoiding Callbacks to Python ', 2, None, '___sec30'),
              (' The Logistic ODE ', 3, None, '___sec31'),
              (' Implementing the van der Pol Equation in FORTRAN ',
               3,
               None,
               '___sec32'),
              (' Example: Solving a Stochastic Differential Equation ',
               2,
               None,
               '___sec33'),
              (' Adaptive Methods ', 1, None, '___sec34'),
              (' The Test Problem ', 2, None, '___sec35'),
              (' Running Simple Methods ', 2, None, '___sec36'),
              (' Running the Runge-Kutta-Fehlberg Method ',
               2,
               None,
               '___sec37'),
              (' Testing More Adaptive Solvers ', 2, None, '___sec38'),
              (' Extensive Testing ', 2, None, '___sec39'),
              (' Solving Partial Differential Equations ',
               1,
               None,
               '___sec40'),
              (' Discretization in Space ', 2, None, '___sec41'),
              (' Implementation ', 2, None, '___sec42'),
              (' Vectorized Code ', 3, None, '___sec43'),
              (' Experiments ', 2, None, '___sec44'),
              (' Inner Workings of the Package ', 1, None, '___sec45'),
              (' Solver Parameters ',
               2,
               'odes:parameters',
               'odes:parameters'),
              (' Solver Classes ', 2, None, '___sec47'),
              (' The Inherited Superclass Constructor ', 3, None, '___sec48'),
              (' Useful Methods ', 3, None, '___sec49'),
              (' The Solve Method ', 3, None, '___sec50'),
              (' Solver Attributes ', 3, None, '___sec51'),
              (' Other Superclasses ', 3, None, '___sec52'),
              (' A Very Simple Subclass ', 2, None, '___sec53'),
              (' A Subclass with More Code ', 2, None, '___sec54'),
              (' A Simple Example of an Implicit Method ',
               2,
               None,
               '___sec55'),
              (' Troubleshooting ', 1, None, '___sec56'),
              (' Constructor takes exactly two arguments, 5 given ',
               2,
               None,
               '___sec57')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript"
 src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- ------------------- main content ---------------------- -->



<center><h1>A Tutorial for the Odespy Interface to ODE Solvers</h1></center>  <!-- document title -->

<p>
<!-- author(s): Hans Petter Langtangen, and Liwei Wang -->

<center>
<b>Hans Petter Langtangen</b> [1, 2]
</center>

<center>
<b>Liwei Wang</b> [2]
</center>

<p>
<!-- institution(s) -->

<center>[1] <b>Center for Biomedical Computing, Simula Research Laboratory</b></center>
<center>[2] <b>Department of Informatics, University of Oslo</b></center>
<p>
<center><h4>May 1, 2015</h4></center> <!-- date -->

<h2>Table of contents</h2>

<p>
<a href="#ode:sec:motivation"> Motivation </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec1"> Traditional Approach </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec5"> Odespy's Unified Interface </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec6"> Methods and Implementations Offered by Odespy </a><br>
<a href="#___sec7"> Installation </a><br>
<a href="#___sec8"> Basic Usage </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec9"> Overview </a><br>
&nbsp; &nbsp; &nbsp; <a href="#ode:sec:exgr"> First Example: Logistic Growth </a><br>
&nbsp; &nbsp; &nbsp; <a href="#ode:sec:exgr:farg"> Parameters in the Right-Hand Side Function </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec18"> Continuing a Previous Simulation </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec19"> Termination Criterion for the Simulation </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec20"> A Class-Based Implementation </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec21"> Using Other Symbols </a><br>
&nbsp; &nbsp; &nbsp; <a href="#ode:sec:ex:osc"> Example: Solving an ODE System </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec23"> The Euler-Cromer Method </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec24"> Testing Several Methods </a><br>
<a href="#___sec25"> More Advanced Implementations </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec26"> Make a Subclass of Class Problem </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec27"> Example: Solving a Complex ODE Problem </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec30"> Avoiding Callbacks to Python </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec33"> Example: Solving a Stochastic Differential Equation </a><br>
<a href="#___sec34"> Adaptive Methods </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec35"> The Test Problem </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec36"> Running Simple Methods </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec37"> Running the Runge-Kutta-Fehlberg Method </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec38"> Testing More Adaptive Solvers </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec39"> Extensive Testing </a><br>
<a href="#___sec40"> Solving Partial Differential Equations </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec41"> Discretization in Space </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec42"> Implementation </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec44"> Experiments </a><br>
<a href="#___sec45"> Inner Workings of the Package </a><br>
&nbsp; &nbsp; &nbsp; <a href="#odes:parameters"> Solver Parameters </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec47"> Solver Classes </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec53"> A Very Simple Subclass </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec54"> A Subclass with More Code </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec55"> A Simple Example of an Implicit Method </a><br>
<a href="#___sec56"> Troubleshooting </a><br>
&nbsp; &nbsp; &nbsp; <a href="#___sec57"> Constructor takes exactly two arguments, 5 given </a><br>
</p>
<p>
The Odespy package makes it easy to specify an ODE problem in
Python and get it solved by a wide variety of different numerical
methods and software.

<h1 id="ode:sec:motivation">Motivation</h1>

<p>
The Odespy package grew out of the desire to have a unified interface
to lots of different methods and software for ODEs. Consider the
ODE problem
$$ y'' = 3 (1 - y^2) y' - y,\quad y(0)=2,\ y'(0)=1, $$

known as the van der Pool oscillator. The solution is
desired at 150 equally spaced time levels in
the interval <code>[0, 30]</code>.

<h2 id="___sec1">Traditional Approach </h2>

<p>
We want to solve this problem
by three well-known routines:

<ol>
 <li> <code>LSODE</code> from ODEPACK (adaptive Adams and BDF methods)</li>
 <li> <code>ode45</code> from MATLAB (adaptive Runge-Kutta 4-5-th order)</li>
 <li> <code>vode</code> from Python (adaptive Adams and BDF methods)</li>
</ol>

All of these routines require the ODE problem to be on the form
\( u'=f(u,t) \), which means that
the second-order differential equation must be
recast as a system of two ODEs,

$$ \frac{d}{dt}u^{(0)} = u^{(1)},\quad \frac{d}{dt}u^{(1)} =3(1-{(u^{(0)})}^2) u^{(1)} - u^{(0)},$$

and we have to identify the two components
of the \( f(u,t) \) function:

$$ f^{(0)}(u^{(0)}, u^{(1)}, t) = u^{(1)}, \quad
   f^{(1)}(u^{(0)}, u^{(1)}, t) =3(1-{(u^{(0)})}^2)u^{(1)} - u^{(0)}$$

The corresponding boundary conditions become
$$ u^{(0)}(0)=2,\quad u^{(1)}(0)=1. $$

<p>
The mentioned ODE software needs a specification of the \( f(u,t) \) formulas
through some user-written function that takes \( u \) and \( t \) as input and
delivers the vector \( f \) as output.

<h3 id="___sec2">LSODE </h3>

<p>
Application of <code>LSODE</code> and other ODEPACK routines requires the
ODE problem to be specified in FORTRAN and the solver to be called
from FORTRAN:
<!-- begin verbatim block  fpro-->
<pre><code>     PROGRAM MAIN
     EXTERNAL F
     INTEGER I, IOPT, IOUT, ISTATE, ITASK, ITOL, IWORK,
    1   LRW, LIW, MF, NEQ, NOUT
     DOUBLE PRECISION ATOL, T, TOUT, RTOL, RWORK, U, URR
     DIMENSION U(2), RWORK(52), IWORK(20), U1(5), U2(5)
     NEQ = 2
C    SET ADAMS METHOD:
     MF = 10
C    LET TOLERANCES BE SCALARS (NOT ARRAYS):
     ITOL = 1
C    USE ONLY ABSOLUTE TOLERANCE:
     RTOL = 0.0D0
     ATOL = 1.0D-6
     LRW = 52
     LIW = 20
C    NUMBER OF TIME STEPS:
     NOUT = 150
C    FINAL TIME:
     TOUT = 30.0D0
C    INITIAL CONDITIONS
     T = 0.0D0
     U(1)= 2.0D0
     U(2) = 0.0D0
     ITASK = 1
     ISTATE = 1
C    CALL ADAPTIVE TIME STEPPING AT EACH OF THE TARGET TIME LEVELS
     DO 100 IOUT = 1, NOUT
       CALL DLSODE(F,NEQ,U,T,TOUT,ITOL,RTOL,ATOL,ITASK,
    1     ISTATE,IOPT,RWORK,LRW,IWORK,LIW,JAC,MF)
       U1(IOUT) = U(1)
       U2(IOUT) = U(2)
       TOUT = TOUT + 2.0D-1
 100 CONTINUE
     END

     SUBROUTINE F(NEQ, T, U, UDOT)
     INTEGER NEQ
     DOUBLE PRECISION T, U, UDOT
     DIMENSION U(2), UDOT(2)
     UDOT(1) = U(2)
     UDOT(2) = 3.0D0*(1.0D0 - U(1)*U(1))*U(2) - U(1)
     RETURN
     END
</code></pre>
<!-- end verbatim block -->

<h3 id="___sec3">MATLAB </h3>

<p>
The problem can be solved with very compact code in MATLAB. The definition
of the ODE system, the \( f(u,t) \) function, is placed in
a function in a file, say <code>myode.m</code>:
<!-- begin verbatim block  mcod-->
<pre><code>function F = myode(t, u);
F(1,1) = u(2)
F(2,1) = 3*(1 - u(1)*u(1))*u(2) - u(1)
</code></pre>
<!-- end verbatim block -->
In MATLAB we can then solve the problem by
<!-- begin verbatim block  ipy-->
<pre><code>&gt;&gt; options = odeset('RelTol',0.0,'AbsTol',1e-6);
&gt;&gt; tspan = [0 30];
&gt;&gt; u0 = [2; 0]
&gt;&gt; [t, u] = ode45('myode', tspan, u0, options]);
</code></pre>
<!-- end verbatim block -->

<h3 id="___sec4">Python </h3>

<p>
Calling up the <code>vode</code> method from the <code>scipy</code> library in Python
also results in fairly compact code:
<!-- begin verbatim block  pycod-->
<pre><code>def f(t, u):
    return [u[1], 3.*(1. - u[0]*u[0])*u[1] - u[0]]

from scipy.integrate import ode
r = ode(f).set_integrator('vode', method='adams',
                          order=10, rol=0, atol=1e-6,
                          with_jacobian=False)
u0 = [2.0, 0.0]
r.set_initial_value(u0, 0)
T = 30
dt = T/150.
u = [];  t = []
while r.successful() and r.t &lt;= T:
    r.integrate(r.t + dt)
    u.append(r.y);  t.append(r.t)
</code></pre>
<!-- end verbatim block -->
Suppose you want to compare these methods and their implementations.
This requires three different main programs, but even worse: three
different implementations of the definition of the mathematical
problem.  Some specifications of \( f \) has the signature \( f(u,t) \) while
others require \( f(t,u) \), and such differences between packages are
often a cause of programming errors.

<h2 id="___sec5">Odespy's Unified Interface </h2>

<p>
The Odespy package provides a unified interface to all the three
mentioned types of methods, which makes it easy to run all of them
in a loop (program <a href="https://github.com/hplgit/odespy/blob/master/doc/src/tutorial/src-odespy/motivation1.py" target="_self"><tt>motivation.py</tt></a>):

<p>
<!-- begin verbatim block  pypro-->
<pre><code>def f(u, t):
    return [u[1], 3.*(1. - u[0]*u[0])*u[1] - u[0]]

u0 = [2.0, 0.0]
import odespy, numpy

for method in odespy.Lsode, odespy.DormandPrince, odespy.Vode:

    solver = method(f, rtol=0.0, atol=1e-6,
                    adams_or_bdf='adams', order=10)
    solver.set_initial_condition(u0)
    t_points = numpy.linspace(0, 30, 150)
    u, t = solver.solve(t_points)
</code></pre>
<!-- end verbatim block -->

<p>
Note in particular that the same <code>f</code> and the same call syntax can be
reused across methods and the underlying software.

<h2 id="___sec6">Methods and Implementations Offered by Odespy </h2>

<p>
Odespy features a unified interface to the following collection of
numerical methods and implementations:

<ul>
  <li> Pure Python implementations of classical explicit schemes such as
    the Forward Euler method (also called Euler);
    Runge-Kutta methods of 2nd, 3rd, and 4th order; Heun's method;
    Adams-Bashforth methods of 2nd, 3rd, and 4th order;
    Adams-Bashforth-Moulton methods of 2nd and 3rd order.</li>
  <li> Pure Python implementations of classical implicit schemes such as
    Backward Euler; 2-step backward scheme; the \( \theta \) rule;
    the Midpoint (or Trapezoidal) method.</li>
  <li> Pure Python implementations of adaptive explicit Runge-Kutta
    methods of type Runge-Kutta-Fehlberg of order (4,5), Dormand-Prince
    of order (4,5), Cash-Karp of order (4,5), Bogacki-Shampine of order (2,3).</li>
  <li> Wrappers for all FORTRAN solvers in <a href="http://www.netlib.org/odepack/" target="_self">ODEPACK</a>.</li>
  <li> Wrappers for the wrappers of FORTRAN solvers in <a href="http://www.scipy.org" target="_self"><tt>scipy</tt></a>:
    <code>vode</code> and <code>zvode</code> (adaptive Adams or BDF from <a href="http://www.netlib.org/ode/vode.f" target="_self">vode.f</a>);
    <code>dopri5</code> (adaptive Dormand-Prince method of order (4,5));
    <code>dop853</code> (adaptive Dormand-Prince method of order 8(5,3));
    <code>odeint</code> (adaptive switching between Adams or BDF from the implementation <code>LSODA</code> in <a href="http://www.netlib.org/odepack/" target="_self">ODEPACK</a>).</li>
  <li> Wrapper for the Runge-Kutta-Chebyshev formulas of order 2 as
    offered by the well-known FORTRAN code <a href="http://www.netlib.org/ode/rkc.f" target="_self"><tt>rkc.f</tt></a>.</li>
  <li> Wrapper for the Runge-Kutta-Fehlberg method of
    order (4,5) as provided by the well-known FORTRAN code <a href="http://www.netlib.org/ode/rkf45.f" target="_self"><tt>rkf45.f</tt></a>.</li>
  <li> Wrapper for the Radau5 method as provided by the well-known FORTRAN code
    <a href="http://www.unige.ch/~hairer/prog/stiff/radau5.f" target="_self"><tt>radau5.f</tt></a>.</li>
  <li> Wrapper for some solvers in the <a href="https://github.com/olivierverdier/odelab" target="_self"><tt>odelab</tt></a> package.</li>
</ul>

The ODE problem can always be specified in Python, but for wrappers of
FORTRAN codes one can also implement the problem in FORTRAN and avoid
callback to Python.

<h1 id="___sec7">Installation </h1>

<p>
The Odespy package is most easily installed using <code>pip</code>:

<p>
<!-- begin verbatim block  sys-->
<pre><code>sudo pip install -e \ 
   git+https://github.com/hplgit/odespy.git#egg=odespy
</code></pre>
<!-- end verbatim block -->
Checking out the source code is almost as easy:
<!-- begin verbatim block  sys-->
<pre><code>git clone git@github.com:hplgit/odespy.git
cd odespy
sudo python setup.py install
</code></pre>
<!-- end verbatim block -->
You will at least also need Python v2.7 and the <a href="http://numpy.scipy.org/" target="_self"><tt>numpy</tt></a> package.  The FORTRAN codes <code>rkc.f</code>,
<code>rkf45.f</code>, <code>radau5.f</code>, and ODEPACK comes with Odespy and are compiled
and installed by <code>setup.py</code>. If you lack a FORTRAN compiler, you
can drop the installation of the FORTRAN solvers by running

<p>
<!-- begin verbatim block  pycod-->
<pre><code>sudo python setup.py install --no-fortran
</code></pre>
<!-- end verbatim block -->

<p>
There have been various problems with compiling Odespy on Windows,
usually related to the Fortran compiler.
One recommended technique is to rely on Anaconda on Windows,
install the <code>ming32</code> compiler, and
then run

<p>
<!-- begin verbatim block  sys-->
<pre><code>Terminal&gt; python setup.py install build --compiler=ming32
</code></pre>
<!-- end verbatim block -->
This may give problems of the type

<p>
<!-- begin verbatim block -->
<pre><code>File &quot;C:\Anaconda\lib\site-packages\numpy\distutils\fcompiler\gnu.py&quot;,
line 333, in get_libraries
raise NotImplementedError(...)
NotImplementedError: Only MS compiler supported with gfortran on win64
</code></pre>
<!-- end verbatim block -->
A remedy is to edit the <code>gnu.py</code> file and comment out the
<code>NotImplementedError</code>:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>else:
    #raise NotImplementedError(&quot;Only MS compiler ...&quot;)
    pass
</code></pre>
<!-- end verbatim block -->

<p>
The Odespy package depends on several additional packages:

<ul>
 <li> <a href="http://scipy.org/" target="_self"><tt>scipy</tt></a> for running the <code>Vode</code> Adams/BDF solver, the
   Dormand-Prince adaptive methods <code>Dop853</code>, and <code>Dopri5</code>,
   and the <code>scipy</code> wrapper <code>odeint</code> of the FORTRAN code <code>LSODA</code>
   (Odespy features an alternative wrapper of the latter, in class <code>Lsoda</code>).</li>
 <li> <a href="http://sympy.org/en/index.html" target="_self"><tt>sympy</tt></a> for running the
   extremely accurate <code>odefun_sympy</code> solver.</li>
 <li> <a href="https://github.com/olivierverdier/odelab" target="_self"><tt>odelab</tt></a>
   for accessing solvers in that package.</li>
</ul>

For plotting you will need <a href="http://matplotlib.sourceforge.net/" target="_self"><tt>matplotlib</tt></a> or <a href="https://github.com/hplgit/scitools/" target="_self"><tt>scitools</tt></a>.

<p>
These packages are readily downloaded and installed by the
standard <code>setup.py</code> script, as shown above.
On Ubuntu and other Debian-based Linux systems the following
line installs all that Odespy may need:
<!-- begin verbatim block  sys-->
<pre><code>sudo apt-get install python-scipy python-nose python-sympy \ 
     python-matplotlib python-scitools python-pip
</code></pre>
<!-- end verbatim block -->

<p>
The <code>odelab</code> package is installed by either
<!-- begin verbatim block  sys-->
<pre><code>pip install -e git+https://github.com/olivierverdier/odelab#egg=odelab
</code></pre>
<!-- end verbatim block -->
or downloading the source and running <code>setup.py</code>:
<!-- begin verbatim block  sys-->
<pre><code>git clone git://github.com/olivierverdier/odelab.git
cd odelab
sudo python setup.py install
</code></pre>
<!-- end verbatim block -->

<p>
<div class="alert alert-block alert-notice alert-text-normal">
<b>Note.</b>
<p>
Despite Odespy's many dependencies on other software, you can run the
basic solvers implemented in pure Python without any additional software
packages.
</div>


<h1 id="___sec8">Basic Usage </h1>

<p>
This section explains how to use Odespy. The general principles and
program steps are first explained. Thereafter, we present a series of
examples with progressive complexity with respect to Python constructs
and numerical methods.

<h2 id="___sec9">Overview </h2>

<p>
A code using Odespy to solve ODEs consists of six steps. These are
outlined in generic form below.

<h3 id="___sec10">Step 1 </h3>

<p>
<em>Write the ODE problem in generic form</em> \( u' = f(u, t) \),
where \( u(t) \) is the unknown function to be solved for, or a vector
of unknown functions of time in case of a system of ODEs.

<h3 id="___sec11">Step 2 </h3>

<p>
<em>Implement the right-hand side function</em> \( f(u, t) \) as a Python function
<code>f(u, t)</code>.  The argument <code>u</code> is either a <code>float</code> object, in case of a
scalar ODE, or a <code>numpy</code> array object, in case of a system of ODEs.
Some solvers in this package also allow implementation of \( f \) in
FORTRAN for increased efficiency.

<h3 id="___sec12">Step 3 </h3>

<p>
<em>Create a solver object</em>
<!-- begin verbatim block  pycod-->
<pre><code>solver = classname(f)
</code></pre>
<!-- end verbatim block -->
where <code>classname</code> is the name of a class in this package implementing
the desired numerical method.

<p>
Many solver classes has a range of parameters that the user can set to
control various parts of the solution process. The parameters are
documented in the doc string of the class (<code>pydoc classname</code> will list
the documentation in a terminal window). One can either specify parameters
at construction time, via extra keyword arguments to the constructor,
<!-- begin verbatim block  pycod-->
<pre><code>solver = classname(f, prm1=value1, prm2=value2, ...)
</code></pre>
<!-- end verbatim block -->
or at any time using the <code>set</code> method:
<!-- begin verbatim block  pycod-->
<pre><code>solver.set(prm1=value1, prm2=value2, prm3=value3)
...
solver.set(prm4=value4)
</code></pre>
<!-- end verbatim block -->

<h3 id="___sec13">Step 4 </h3>

<p>
<em>Set the initial condition</em> \( u(0)=U_0 \),
<!-- begin verbatim block  pycod-->
<pre><code>solver.set_initial_condition(U0)
</code></pre>
<!-- end verbatim block -->
where <code>U0</code> is either a number, for a scalar ODE, or a sequence (list, tuple,
<code>numpy</code> array), for a system of ODEs.

<h3 id="___sec14">Step 5 </h3>

<p>
<em>Solve the ODE problem</em>, which means to compute \( u(t) \) at
some discrete user-specified time points \( t_1, t_2, \ldots, t_N \).
<!-- begin verbatim block  pycod-->
<pre><code>T = ...  # end time
time_points = numpy.linspace(0, T, N+1)
u, t = solver.solve(time_points)
</code></pre>
<!-- end verbatim block -->
In case of a scalar ODE, the returned solution <code>u</code> is a one-dimensional
<code>numpy</code> array where <code>u[i]</code> holds the solution at time point <code>t[i]</code>.
For a system of ODEs, the returned <code>u</code> is a two-dimensional <code>numpy</code>
array where <code>u[i,j]</code> holds the solution of the \( j \)-th unknown
function at the \( i \)-th time point <code>t[i]</code> (\( u_j(t_i) \) in mathematics
notation).

<p>
By giving the parameter <code>disk_storage=True</code> to the solver's constructor,
the returned <code>u</code> array is memory mapped (i.e., of type <code>numpy.memmap</code>)
such that all the data are stored on file, but parts of the array can
be efficiently accessed.

<p>
The <code>time_points</code> array specifies the time points where we want the
solution to be computed. The returned array <code>t</code> is the same as
<code>time_points</code>.  The simplest numerical methods in the Odespy
package apply the <code>time_points</code> array directly for the time stepping.
That is, the time steps used are given by
<!-- begin verbatim block  pycod-->
<pre><code>time_points[i] - time_points[i-1]  #  i=0,1,...,len(time_points)-1
</code></pre>
<!-- end verbatim block -->
The adaptive schemes typically compute between each time point in
the <code>time_points</code> array, making this array a specification where
values of the unknowns are desired.

<p>
The <code>solve</code> method in solver classes also allows a second argument,
<code>terminate</code>, which is a user-implemented Python function specifying
when the solution process is to be terminated. For example,
terminating when the solution reaches an asymptotic (known) value
<code>a</code> can be done by
<!-- begin verbatim block  pycod-->
<pre><code>def terminate(u, t, step_no):
    # u and t are arrays. Most recent solution is u[step_no].
    tolerance = 1E-6
    return abs(u[step_no] - a) &lt; tolerance

u, t = solver.solve(time_points, terminate)
</code></pre>
<!-- end verbatim block -->
The arguments transferred to the <code>terminate</code> function are the
solution array <code>u</code>, the corresponding time points <code>t</code>, and
an integer <code>step_no</code> reflecting the most recently computed <code>u</code>
value. That is, <code>u[step_no]</code> is most recently computed value of \( u \).
(The array data <code>u[step_no+1:]</code> will typically be zero as these
are uncomputed future values.)

<h3 id="___sec15">Step 6 </h3>

<p>
<em>Extract solution components</em> for plotting and further analysis.
Since the <code>u</code> array returned from <code>solver.solve</code> stores all unknown
functions at all discrete time levels, one usually wants to extract
individual unknowns as one-dimensional arrays. Here is an example
where unknown number \( 0 \) and \( k \) are extracted in individual arrays
and plotted:
<!-- begin verbatim block  pycod-->
<pre><code>u_0 = u[:,0]
u_k = u[:,k]

from matplotlib.pyplot import plot, show
plot(t, u_0, t, u_k)
show()
</code></pre>
<!-- end verbatim block -->

<h2 id="ode:sec:exgr">First Example: Logistic Growth</h2>

<p>
Our first example concerns the simple scalar ODE problem

$$
\frac{du}{dt}=au\left(1-\frac{u}{R}\right),\quad u(0)=A,
$$

where \( A>0 \), \( a>0 \), and \( R>0 \) are known constants. This is
a common model for population dynamics in ecology where \( u \) is the
number of individuals, \( a \) the initial growth rate, \( R \) is the
maximum number of individuals that the environment allows (the so-called
<em>carrying capacity</em> of the environment).

<p>
Using a standard
Runge-Kutta method of order four, the code for solving the problem in
the time interval \( [0,10] \) with \( N=30 \) time steps, looks like this
(program <a href="https://github.com/hplgit/odespy/blob/master/doc/src/tutorial/src-odespy/logistic1.py" target="_self"><tt>logistic1.py</tt></a>):

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def f(u, t):
    return a*u*(1 - u/R)

a = 2
R = 1E+5
A = 1

import odespy
solver = odespy.RK4(f)
solver.set_initial_condition(A)

from numpy import linspace, exp
T = 10  # end of simulation
N = 30  # no of time steps
time_points = linspace(0, T, N+1)
u, t = solver.solve(time_points)
</code></pre>
<!-- end verbatim block -->

<p>
With the <code>RK4</code> method and other non-adaptive methods
the time steps are dictated by the <code>time_points</code> array.
A constant time step of size is implied in the present example.
Running an alternative numerical method just means replacing <code>RK4</code> by, e.g.,
<code>RK2</code>, <code>ForwardEuler</code>, <code>BackwardEuler</code>, <code>AdamsBashforth2</code>, etc.

<p>
We can easily plot the numerical solution and compare with the exact
solution (which is known for this equation):

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def u_exact(t):
    return R*A*exp(a*t)/(R + A*(exp(a*t) - 1))

from matplotlib.pyplot import *

plot(t, u, 'r-',
     t, u_exact(t), 'bo')
savefig('tmppng'); savefig('tmp.pdf')
show()
</code></pre>
<!-- end verbatim block -->

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 1:  Solution of the logistic equation with the 4-th order Runge-Kutta method (solid line) and comparison with the exact solution (dots). </p></center>
<p><img src="fig-odespy/logistic1.png" align="bottom" width=400></p>
</center>

<p>
All the examples in this tutorial are found in the GitHub directory
<a href="https://github.com/hplgit/odespy/blob/master/doc/src/tutorial/src-odespy/" target="_self"><tt>https://github.com/hplgit/odespy/blob/master/doc/src/tutorial/src-odespy/</tt></a>.
If you download the tarball or clone the GitHub repository, the examples
reside in the directory <code>doc/src/odespy/src-odespy</code>.

<h2 id="ode:sec:exgr:farg">Parameters in the Right-Hand Side Function</h2>

<p>
The right-hand side function and all physical parameters are often
lumped together in a class, for instance,

<p>
<!-- begin verbatim block  pycod-->
<pre><code>class Logistic:
    def __init__(self, a, R, A):
        self.a = a
        self.R = R
        self.A = A

    def f(self, u, t):
        a, R = self.a, self.R  # short form
        return a*u*(1 - u/R)

    def u_exact(self, t):
        a, R, A = self.a, self.R, self.A  # short form
        return R*A*exp(a*t)/(R + A*(exp(a*t) - 1))
</code></pre>
<!-- end verbatim block -->

<p>
Note that introducing local variables like <code>a</code> and <code>R</code>, instead of
using <code>self.a</code> and <code>self.A</code>, makes the code closer to the mathematics.
This can be convenient when proof reading the implementation of
complicated ODEs.

<p>
The numerical solution is computed by

<p>
<!-- begin verbatim block  pycod-->
<pre><code>import odespy
problem = Logistic(a=2, R=1E+5, A=1)
solver = odespy.RK4(problem.f)
solver.set_initial_condition(problem.A)

T = 10  # end of simulation
N = 30  # no of time steps
time_points = linspace(0, T, N+1)
u, t = solver.solve(time_points)
</code></pre>
<!-- end verbatim block -->
The complete program is available in the file program <a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/logistic2.py" target="_self"><tt>logistic2.py</tt></a>.

<p>
Instead of having the problem parameters <code>a</code> and <code>R</code> in the ODE as
global variables or in a class, we may include them as extra arguments
to <code>f</code>, either as positional arguments or as keyword
arguments. Positional arguments can be sent to <code>f</code> via the constructor
argument <code>f_args</code> (a list/tuple of variables), while a dictionary
<code>f_kwargs</code> is used to transfer keyword arguments to <code>f</code> via the
constructor. Here is an example on using keyword arguments:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def f(u, t, a=1, R=1):
    return a*u*(1 - u/R)

A = 1

import odespy
solver = odespy.RK4(f, f_kwargs=dict(a=2, R=1E+5))
</code></pre>
<!-- end verbatim block -->

<p>
In general, a mix
of positional and keyword arguments can be used in <code>f</code>:
<!-- begin verbatim block  pycod-->
<pre><code>def f(u, t, arg1, arg2, arg3, ..., kwarg1=val1, kwarg2=val2, ...):
    ...

solver = odespy.classname(f,
                    f_args=[arg1, arg2, arg3, ...],
                    f_kwargs=dict(kwarg1=val1, kwarg2=val2, ...))

# Alternative setting of f_args and f_kwargs
solver.set(f_args=[arg1, arg2, arg3, ...],
           f_kwargs=dict(kwarg1=val1, kwarg2=val2, ...))
</code></pre>
<!-- end verbatim block -->
Solvers will call <code>f</code> as <code>f(u, t, *f_args, **f_kwargs)</code>.

<h2 id="___sec18">Continuing a Previous Simulation </h2>

<p>
It is easy to simulate for some time interval \( [0, T_1] \),
then continue with \( u(T_1) \) as new initial condition and simulate for
\( t \) in \( [T_1, T_2] \) and so on. Let us divide the time
domain into subdomains and compute the solution for
each subdomain in sequence. The following program performs the steps
(<a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/logistic4.py" target="_self"><tt>logistic4.py</tt></a>).

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def f(u, t, a=1, R=1):
    return a*u*(1 - u/R)

A = 1

import odespy, numpy
from matplotlib.pyplot import plot, hold, show, axis

solver = odespy.RK4(f, f_kwargs=dict(a=2, R=1E+5))

# Split time domain into subdomains and
# integrate the ODE in each subdomain
T = [0, 1, 4, 8, 12]     # subdomain boundaries

N_tot = 30               # total no of time steps
dt = float(T[-1])/N_tot  # time step, kept fixed
u = []; t = []           # collectors for u and t in each domain

for i in range(len(T)-1):
    T_interval = T[i+1] - T[i]
    N = int(round(T_interval/dt))
    time_points = numpy.linspace(T[i], T[i+1], N+1)

    solver.set_initial_condition(A)  # at time_points[0]
    print 'Solving in [%s, %s] with %d intervals' % \ 
          (T[i], T[i+1], N)
    ui, ti = solver.solve(time_points)
    A = ui[-1]  # newest ui value is next initial condition

    plot(ti, ui)
    hold('on')

    u.append(ui);  t.append(ti)

axis([0, T[-1], -0.1E+5, 1.1E+5])
# Can concatenate all the elements of u and t, if desired
u = numpy.concatenate(u);  t = numpy.concatenate(t)
savefig('tmppng'); savefig('tmp.pdf')
</code></pre>
<!-- end verbatim block -->

<h2 id="___sec19">Termination Criterion for the Simulation </h2>

<p>
We know that the solution \( u \) of the logistic equation approaches
\( R \) as \( t\rightarrow\infty \). Instead of
using a trial and error process for determining an appropriate
time integral for integration, the <code>solver.solve</code> method accepts
a user-defined function <code>terminate</code> that can be used to implement
a criterion for terminating the solution process.
Mathematically, the relevant criterion is
\( ||u-R|| < \hbox{tol} \), where tol is an acceptable
tolerance, say \( 100 \) in the present case where \( R=10^5 \).
The <code>terminate</code> function implements the criterion
and returns true if the criterion is met:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def terminate(u, t, step_no):
    &quot;&quot;&quot;u[step_no] holds (the most recent) solution at t[step_no].&quot;&quot;&quot;
    return abs(u[step_no] - R) &lt; tol
</code></pre>
<!-- end verbatim block -->

<p>
Note that the simulation is anyway stopped for \( t > T \) so \( T \)
must be large enough for the termination criterion to be reached (if not,
a warning will be issued).
With a <code>terminate</code> function it is also convenient to specify the
time step <code>dt</code> and not the total number of time steps.

<p>
A complete program can be as follows (<a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/logistic5.py" target="_self"><tt>logistic5.py</tt></a>):

<p>
<!-- begin verbatim block  pypro-->
<pre><code>def f(u, t):
    return a*u*(1 - u/R)

a = 2
R = 1E+5
A = 1

import odespy, numpy
solver = odespy.RK4(f)
solver.set_initial_condition(A)

T = 20  # end of simulation
dt = 0.25
N = int(round(T/dt))
time_points = numpy.linspace(0, T, N+1)

tol = 100   # tolerance for termination criterion

def terminate(u, t, step_no):
    &quot;&quot;&quot;u[step_no] holds (the most recent) solution at t[step_no].&quot;&quot;&quot;
    return abs(u[step_no] - R) &lt; tol

u, t = solver.solve(time_points, terminate)
print 'Final u(t=%g)=%g' % (t[-1], u[-1])

from matplotlib.pyplot import *
plot(t, u, 'r-')
savefig('tmppng'); savefig('tmp.pdf')
show()
</code></pre>
<!-- end verbatim block -->

<h2 id="___sec20">A Class-Based Implementation </h2>

<p>
The previous code example can be recast into a more class-based
("object-oriented programming") example. We lump all data related
to the problem (the "physics") into a problem class <code>Logistic</code>, while
all data related to the numerical solution and its quality are
taken care of by class <code>Solver</code>. The code below illustrates
the ideas (<a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/logistic26py" target="_self"><tt>logistic6.py</tt></a>):

<p>
<!-- begin verbatim block  pypro-->
<pre><code>import numpy as np
import matplotlib.pyplot as plt
import odespy

class Logistic:
    def __init__(self, a, R, A, T):
        &quot;&quot;&quot;
        a` is (initial growth rate), `R` the carrying capacity,
        `A` the initial amount of u, and `T` is some (very) total
        simulation time when `u` is very close to the asymptotic
        value `R`.
        &quot;&quot;&quot;
        self.a, self.R, self.A = a, R, A
        self.tol = 0.01*R # tolerance for termination criterion

    def f(self, u, t):
        &quot;&quot;&quot;Right-hand side of the ODE.&quot;&quot;&quot;
        a, R = self.a, self.R  # short form
        return a*u*(1 - u/R)

    def terminate(self, u, t, step_no):
        &quot;&quot;&quot;u[step_no] holds solution at t[step_no].&quot;&quot;&quot;
        return abs(u[step_no] - self.R) &lt; self.tol

    def u_exact(self, t):
        a, R, A = self.a, self.R, self.A  # short form
        return R*A*np.exp(a*t)/(R + A*(np.exp(a*t) - 1))


class Solver:
    def __init__(self, problem, dt, method='RK4'):
        self.problem = problem
        self.dt = dt
        self.method_class = eval('odespy.' + method)
        self.N = int(round(T/dt))

    def solve(self):
        self.solver = self.method_class(self.problem.f)
        self.solver.set_initial_condition(self.problem.A)
        time_points = np.linspace(0, self.problem.T, self.N+1)
        self.u, self.t = self.solver.solve(
            time_points, self.problem.terminate)
        print 'Final u(t=%g)=%g' % (t[-1], u[-1])

    def plot(self):
        plt.plot(self.t, self.u, 'r-',
                 self.t, self.u_exact(self.t), 'bo')
        plt.legend(['numerical', 'exact'])
        plt.savefig('tmp.png'); plt.savefig('tmp.pdf')
        plt.show()

def main():
    problem = Logistic(a=2, R=1E+5, A=1, T=20)
    solver = Solver(problem, dt=0.25, method='RK4')
    solver.solve()
    solver.plot()

if __name__ == '__main__':
    main()
</code></pre>
<!-- end verbatim block -->

<h2 id="___sec21">Using Other Symbols </h2>

<p>
The Odespy package applies <code>u</code> for the unknown function or vector of
unknown functions and <code>t</code> as the name of the independent
variable. Many problems involve other symbols for functions and
independent variables. These symbols should be reflected in the user's
code.  For example, here is a coding example involving the logistic
equation written as \( y'(x)=au(x)(1-u(x)/R(x)) \), where now a variable
\( R=R(x) \) is considered. Following the setup from the very first
program above solving the logistic ODE, we can easily introduce our
own nomenclature (<a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/logistic7.py" target="_self"><tt>logistic7.py</tt></a>):

<p>
<!-- begin verbatim block  pypro-->
<pre><code>def f(y, x):
    return a*y*(1 - y/R)

a = 2;  R = 1E+5;  A = 1

import odespy, numpy
solver = odespy.RK4(f)
solver.set_initial_condition(A)

L = 10  # end of x domain
N = 30  # no of time steps
x_points = numpy.linspace(0, L, N+1)
y, x = solver.solve(x_points)

from matplotlib.pyplot import *
plot(x, y, 'r-')
xlabel('x'); ylabel('y')
show()
</code></pre>
<!-- end verbatim block -->

<p>
As shown, we use <code>y</code> for <code>u</code>, <code>x</code> for <code>t</code>, and <code>x_points</code> instead
of <code>time_points</code>.

<h2 id="ode:sec:ex:osc">Example: Solving an ODE System</h2>

<p>
We shall now explain how to solve a system of ODEs using a scalar
second-order ODE as starting point.
The angle \( \theta \) of a pendulum with mass \( m \) and length \( L \)
is governed by the equation
(neglecting air resistance for simplicity)

$$
mL\ddot\theta + mg\sin\theta = 0,\quad \theta (0)=\Theta,\ 
\dot\theta (0)=0 .
$$

A dot over \( \theta \) implies differentiation with respect to time.
The ODE can be written as \( \ddot\theta + c\sin\theta=0 \) by
introducing \( c = g/L \).

<p>
This problem must be expressed as a first-order ODE system if it is
going to be solved by the tools in the Odespy package.
Introducing \( \omega = \dot\theta \) (the angular velocity) as auxiliary
unknown, we get the system
$$
\begin{align*}
\dot\theta &= \omega,\\ 
\dot\omega &= -c\sin\theta,
\end{align*}
$$

with \( \theta(0)=\Theta \) and \( \omega(0)=0 \).

<p>
Now the <code>f</code> function must return a list or array with the two
right-hand side functions:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def f(u, t):
    theta, omega = u
    return [omega, -c*sin(theta)]
</code></pre>
<!-- end verbatim block -->

<p>
Note that when we have a system of ODEs with <code>n</code> components, the <code>u</code>
object sent to the <code>f</code> function is an array of length <code>n</code>,
representing the value of all components in the ODE system at time <code>t</code>.
Here we extract the two components of <code>u</code> in separate local variables
with names equal to what is used in the mathematical description of
the current problem.

<p>
The initial conditions must be specified as a list:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>solver = odespy.Heun(f)
solver.set_initial_condition([Theta, 0])
</code></pre>
<!-- end verbatim block -->

<p>
To specify the time points we here first decide on a number of periods
(oscillations back and forth) to simulate and then on the time resolution
of each period. Note that when \( \Theta \) is small we can replace
\( \sin\theta \) by \( \theta \) and find an analytical
solution
\( \theta (t)=\Theta\cos\left(\sqrt{c}t\right) \)
whose period is \( 2\pi/\sqrt{c} \). We use this expression
as an approximation for the period also when \( \Theta \) is not
small.

<p>
<!-- begin verbatim block  pycod-->
<pre><code>freq = sqrt(c)      # frequency of oscillations when Theta is small
period = 2*pi/freq  # the period of the oscillations
T = 10*period       # final time
N_per_period = 20   # resolution of one period
N = N_per_period*period
time_points = numpy.linspace(0, T, N+1)

u, t = solver.solve(time_points)
</code></pre>
<!-- end verbatim block -->

<p>
The <code>u</code> returned from <code>solver.solve</code> is a two-dimensional array, where the
columns hold the various solution functions of the ODE system. That is,
the first column holds \( \theta \) and the second column holds
\( \omega \). For convenience we extract the individual solution
components in individual arrays:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>theta = u[:,0]
omega = u[:,1]

from matplotlib.pyplot import *
plot(t, theta, 'r-')
savefig('tmppng'); savefig('tmp.pdf')
show()
</code></pre>
<!-- end verbatim block -->
The complete program is available in the file <a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/osc1a.py" target="_self"><tt>osc1a.py</tt></a>.

<p>
Looking at the plot reveals that the numerical solution has
an alarming feature: the amplitude grows (indicating increasing
energy in the system). Changing <code>T</code> to 28 periods instead of 10
makes the numerical solution explode.
The increasing amplitude is a numerical artifact that some of the simple
solution methods suffer from.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 2:  Heun's method used to simulate oscillations of a pendulum. </p></center>
<p><img src="fig-odespy/osc1a.png" align="bottom" width=500></p>
</center>

<p>
Using a more sophisticated method, say the 4-th order Runge-Kutta method,
is just a matter of substituting <code>Heun</code> by <code>RK4</code>:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>solver = odespy.RK4(f)
solver.set_initial_condition([Theta, 0])
freq = sqrt(c)      # frequency of oscillations when Theta is small
period = 2*pi/freq  # the period of the oscillations
T = 10*period       # final time
N_per_period = 20   # resolution of one period
N = N_per_period*period
time_points = numpy.linspace(0, T, N+1)

u, t = solver.solve(time_points)

theta = u[:,0]
omega = u[:,1]

from matplotlib.pyplot import *
plot(t, theta, 'r-')
savefig('tmppng'); savefig('tmp.pdf')
show()
</code></pre>
<!-- end verbatim block -->
The amplitude now becomes (almost) constant in time as expected.
Another very good and popular method for this problem is presented next.

<h2 id="___sec23">The Euler-Cromer Method </h2>

<p>
Physicists will most likely
solve the model problem in the section <a href="#ode:sec:ex:osc">Example: Solving an ODE System</a> by
the Euler-Cromer method. For a single degree of freedom system,

$$ \ddot x + f(x, \dot x, t) = 0,$$

typically modeling an oscillatory system, the Euler-Cromer method
writes the system as two ODEs,

$$
\begin{align*}
\dot v &= -g(x, v, t),\\ 
\dot x &= v\thinspace .
\end{align*}
$$

A Forward Euler scheme is used for the first equation, while a Backward
Euler scheme is used for the second:

$$
\begin{align*}
v^{n+1} &= v^n - \Delta t\, g(x^n, v^n, n\Delta t),\\ 
x^{n+1} &= x^n + \Delta t\,v^{n+1}\thinspace .
\end{align*}
$$

The two first-order methods used in this symmetric fashion results in
a second-order method that will preserve the amplitude of the oscillations.

<p>
For general multi degree of freedom systems, we have some vector ODE
arising from, typically, Newton's second law of motion,

$$ \ddot{\boldsymbol{r}} + \boldsymbol{g}(\boldsymbol{r},\dot{\boldsymbol{r}},t) = 0\thinspace .$$

This is rewritten as

$$
\begin{align*}
\dot{\boldsymbol{v}} &= -\boldsymbol{g}(\boldsymbol{r}, \boldsymbol{v}, t),\\ 
\dot{\boldsymbol{r}} &= \boldsymbol{v},
\end{align*}
$$

and discretized as

$$
\begin{align*}
\boldsymbol{v}^{n+1} &= \boldsymbol{v}^n -\Delta t\,\boldsymbol{g}(\boldsymbol{r}^n, \boldsymbol{v}^n, t),\\ 
\boldsymbol{r}^{n+1} &= \boldsymbol{r}^n + \Delta t\,\boldsymbol{v}^{n+1}\thinspace .
\end{align*}
$$

<p>
The convention in Odespy is to group all the unknowns as velocity and position
for each degree of freedom. That is, if the component form of \( \boldsymbol{r} \)
and \( \boldsymbol{v} \) is written as

$$ \boldsymbol{r} = (r^{(0)}, r^{(0)}, \ldots, r^{(N)}),
\quad \boldsymbol{v} = (v^{(0)}, v^{(0)}, \ldots, v^{(N)}),
$$

the \( u \) vector of all unknowns in the Euler-Cromer method in Odespy
must be

$$ u=(v^{(0)}, r^{(0)}, v^{(1)}, r^{(1)}, \ldots,v^{(N)}, r^{(N)})\thinspace .$$

The corresponding set of ODEs are

$$
\begin{align*}
\dot v^{(0)} &= -g^{(0)}(\boldsymbol{r}, \boldsymbol{v}, t),\\ 
\dot r^{(0)} &= v^{(0)},\\ 
\dot v^{(1)} &= -g^{(1)}(\boldsymbol{r}, \boldsymbol{v}, t),\\ 
\dot r^{(1)} &= v^{(1)},\\ 
&\cdots\\ 
\dot v^{(N)} &= -g^{(N)}(\boldsymbol{r}, \boldsymbol{v}, t),\\ 
\dot r^{(N)} &= v^{(N)}\thinspace .
\end{align*}
$$

<p>
For the particular case of a pendulum we write our system as

$$
\begin{align*}
\dot\omega &= -c\sin\theta,\\ 
\dot\theta &= \omega,
\end{align*}
$$

and let \( u=(\omega, \theta) \). The relevant right-hand side function becomes

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def f(u, t):
    omega, theta = u
    return [-c*sin(theta), omega]
</code></pre>
<!-- end verbatim block -->

<p>
With some imports,

<p>
<!-- begin verbatim block  pycod-->
<pre><code>import odespy
from numpy import *
from matplotlib.pyplot import *
</code></pre>
<!-- end verbatim block -->
we can write the rest of the program in a standard fashion:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>c = 1
Theta0_degrees = 30

solver = odespy.EulerCromer(f)
Theta0 = Theta0_degrees*pi/180
solver.set_initial_condition([0, Theta0])
# Solve for num_periods periods using formulas for small theta
freq = sqrt(c)          # frequency of oscillations
period = 2*pi/freq      # one period
N = 40                  # intervals per period
dt = period/N           # time step
num_periods = 10
T = num_periods*period  # total simulation time

time_points = linspace(0, T, num_periods*N+1)
u, t = solver.solve(time_points)

# Extract components and plot theta
theta = u[:,1]
omega = u[:,0]
theta_linear = lambda t: Theta0*cos(sqrt(c)*t)
plot(t, theta, t, theta_linear(t))
legend(['Euler-Cromer', 'Linearized problem'], loc='lower left')
</code></pre>
<!-- end verbatim block -->

<p>
With \( \Theta_0 \) as 30 degrees, the fully nonlinear solution is
slightly out of phase with the solution of the linearized
problem \( \ddot\theta + c\theta =0 \), see Figure <a href="#ode:sec:EC:fig1">3</a>.
As \( \Theta_0\rightarrow 0 \), the two curves approach each other.
The Euler-Cromer method is significantly better than Heun's method
used in the previous section and reproduces the exact amplitude.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 3:  Euler-Cromer method applied to the pendulum problem. <div id="ode:sec:EC:fig1"></div> </p></center>
<p><img src="fig-odespy/osc_EC_30.png" align="bottom" width=500></p>
</center>

<h2 id="___sec24">Testing Several Methods </h2>

<p>

<!-- begin inline comment -->
<font color="red">(<b>hpl 1</b>: After Euler-Cromer, change the order of the ODEs and unknowns!)</font>
<!-- end inline comment -->

<p>
We shall now make a more advanced solver by
extending the pendulum example. More specifically, we shall

<ul>
  <li> represent the right-hand side function as class,</li>
  <li> compare several different solvers,</li>
  <li> compute error of numerical solutions.</li>
</ul>

Since we want to compare numerical errors in the various
solvers we need a test problem where the exact solution is known.
Approximating \( \sin(\theta) \) by \( \theta \)
(valid for small \( \theta \)), gives the ODE system

$$
\begin{align*}
\dot\theta &= \omega,\\ 
\dot\omega &= -c\theta,
\end{align*}
$$

with \( \theta(0)=\Theta \) and \( \omega(0)=0 \).

<p>
Right-hand side functions with parameters can be handled by
including extra arguments via the <code>f_args</code> and <code>f_kwargs</code> functionality,
or by using a class where the parameters are attributes and
an <code>f</code> method defines \( f(u,t) \).
The section <a href="#ode:sec:exgr:farg">Parameters in the Right-Hand Side Function</a> exemplifies the details.
A minimal class representation of the right-hand side
function in the present case looks like this:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>class Problem:
    def __init__(self, c, Theta):
        self.c, self.Theta = float(c), float(Theta)

    def f(self, u, t):
        theta, omega = u;  c = self.c
        return [omega, -c*theta]

problem = Problem(c=1, Theta=pi/4)
</code></pre>
<!-- end verbatim block -->
It would be convenient to add an attribute <code>period</code> which holds
an estimate of the period of oscillations as we need this for
deciding on the complete time interval for solving the differential
equations. An appropriate extension of class <code>Problem</code> is therefore

<p>
<!-- begin verbatim block  pycod-->
<pre><code>class Problem:
    def __init__(self, c, Theta):
        self.c, self.Theta = float(c), float(Theta)

        self.freq = sqrt(c)
        self.period = 2*pi/self.freq

    def f(self, u, t):
        theta, omega = u;  c = self.c
        return [omega, -c*theta]

problem = Problem(c=1, Theta=pi/4)
</code></pre>
<!-- end verbatim block -->

<p>
The second extension is to loop over many solvers. All
solvers can be listed by
<!-- begin verbatim block  ipy-->
<pre><code>&gt;&gt;&gt; import odespy
&gt;&gt;&gt; methods = list_all_solvers()
&gt;&gt;&gt; for method in methods:
...   print method
...
AdamsBashMoulton2
AdamsBashMoulton3
AdamsBashforth2
...
Vode
lsoda_scipy
odefun_sympy
odelab
</code></pre>
<!-- end verbatim block -->
A similar function, <code>list_available_solvers</code>, returns a list of the
names of the solvers that are available in the current installation
(e.g., the <code>Vode</code> solver is only available if the comprehensive
<code>scipy</code> package is installed).
This is the list that is usually most relevant.

<p>
For now we explicitly choose a subset of the commonly available solvers:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>import odespy
solvers = [
    odespy.ThetaRule(problem.f, theta=0),   # Forward Euler
    odespy.ThetaRule(problem.f, theta=0.5), # Midpoint method
    odespy.ThetaRule(problem.f, theta=1),   # Backward Euler
    odespy.RK4(problem.f),
    odespy.MidpointIter(problem.f, max_iter=2, eps_iter=0.01),
    odespy.LeapfrogFiltered(problem.f),
    ]
</code></pre>
<!-- end verbatim block -->
To see what a method is and its arguments to the constructor, invoke
the doc string of the class, e.g., <code>help(ThetaRule)</code> inside a
Python shell like IPython, or run <code>pydoc odespy.ThetaRule</code> in a
terminal window, or invoke the <a href="http://hplgit.github.com/odespy/doc/api/" target="_self">Odespy API documentation</a>.

<p>
It will be evident that the <code>ThetaRule</code> solver with <code>theta=0</code> and
<code>theta=1</code> (Forward and Backward Euler methods) gives growing and
decaying amplitudes, respectively, while the other solvers are
capable of reproducing the constant amplitude of the oscillations of
in the current mathematical model.

<p>
The loop over the chosen solvers may look like

<p>
<!-- begin verbatim block  pycod-->
<pre><code>N_per_period = 20
T = 3*problem.period   # final time
import numpy
import matplotlib.pyplot as plt
legends = []

for solver in solvers:
    solver_name = str(solver)  # short description of solver
    print solver_name

    solver.set_initial_condition([problem.Theta, 0])
    N = N_per_period*problem.period
    time_points = numpy.linspace(0, T, N+1)

    u, t = solver.solve(time_points)

    theta = u[:,0]
    legends.append(solver_name)
    plt.plot(t, theta)
    plt.hold('on')
plt.legend(legends)
plotfile = __file__[:-3]
plt.savefig(plotfile + '.png'); plt.savefig(plotfile + '.pdf')
plt.show()
</code></pre>
<!-- end verbatim block -->
A complete program is available as <a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/osc2.py" target="_self"><tt>osc2.py</tt></a>.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 4:  Comparison of methods for solving the ODE system for a pendulum. </p></center>
<p><img src="fig-odespy/osc2.png" align="bottom" width=500></p>
</center>

<p>
We can extend this program to compute the error in each numerical
solution for different time step sizes.
Let <code>results</code> be a dictionary with the method name as
key, containing two sub dictionaries <code>dt</code> and <code>error</code>, which hold
a sequence of time steps and a sequence of corresponding
errors, respectively. The errors are computed by subtracting
the numerical solution from the exact solution,
<!-- begin verbatim block  pycod-->
<pre><code>theta_exact = lambda t: problem.Theta*numpy.cos(sqrt(problem.c)*t)
u, t = solver.solve(time_points)
theta = u[:,0]
error = numpy.abs(theta_exact(t) - theta)
</code></pre>
<!-- end verbatim block -->
The so-called L2 norm of the <code>error</code> array is a suitable
scalar error measure (square root of total error squared and integrated,
here numerically):
<!-- begin verbatim block  pycod-->
<pre><code>error_L2 = sqrt(numpy.sum(error**2)/dt)
</code></pre>
<!-- end verbatim block -->
where <code>dt</code> is the time step size.

<p>
Typical loops over solvers and resolutions look as follows (<a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/osc3.py" target="_self"><tt>osc3.py</tt></a>):

<p>
<!-- begin verbatim block  pycod-->
<pre><code>try:
    num_periods = int(sys.argv[1])
except IndexError:
    num_periods = 8  # default

T = num_periods*problem.period       # final time
results = {}
resolutions = [10, 20, 40, 80, 160]  # intervals per period
import numpy

for solver in solvers:
    solver_name = str(solver)
    results[solver_name] = {'dt': [], 'error': []}

    solver.set_initial_condition([problem.Theta, 0])

    for N_per_period in resolutions:
        N = N_per_period*num_periods
        time_points = numpy.linspace(0, T, N+1)

        u, t = solver.solve(time_points)

        theta = u[:,0]
        error = numpy.abs(theta_exact(t) - theta)
        error_L2 = sqrt(numpy.sum(error**2)/N)
        if not numpy.isnan(error_L2):  # drop nan (overflow)
            results[solver_name]['dt'].append(t[1] - t[0])
            results[solver_name]['error'].append(error_L2)
</code></pre>
<!-- end verbatim block -->

<p>
Assuming the error to be of the form \( C\Delta t^r \), we can estimate
\( C \) and \( r \) from two consecutive experiments to obtain a sequence
of \( r \) values which (hopefully) convergences to a value that we can
view as the empirical convergence rate of a method.
Given the sequence of time steps and errors, we can compare two
experiments \( i \) and \( i-1 \), with errors \( E_{i}=C\Delta t_i^r \), and
estimate \( r=\ln(E_i/E_{i-1})/\ln(\Delta t_i/\Delta t_{i-1}) \):

<p>
<!-- begin verbatim block  pycod-->
<pre><code>from math import log
print '\n\nConvergence results for %d periods' % num_periods
for solver_name in results:
    r_h = results[solver_name]['dt']
    r_E = results[solver_name]['error']
    rates = [log(r_E[i]/r_E[i-1])/log(r_h[i]/r_h[i-1]) for i
             in range(1, len(r_h))]
    # Reformat rates with 1 decimal for rate
    rates = ', '.join(['%.1f' % rate for rate in rates])
    print '%-20s r: %s E_min=%.1E' % \ 
          (solver_name, rates, min(results[solver_name]['error']))
</code></pre>
<!-- end verbatim block -->

<p>
With 4 periods we get
<!-- begin verbatim block  dat-->
<pre><code>ThetaRule(theta=0)   r: 4.2,  2.4, 1.7, 1.3 E_min=1.9E-01
LeapfrogFiltered     r: 10.3, 0.3, 0.5, 0.7 E_min=1.8E-01
ThetaRule(theta=1)   r: 0.2,  0.4, 0.6, 0.8 E_min=1.3E-01
ThetaRule            r: 2.3,  2.0, 2.0, 2.0 E_min=2.1E-03
RK4                  r: 4.0,  4.0, 4.0, 4.0 E_min=1.6E-07
Leapfrog             r: 2.2,  2.0, 2.0, 2.0 E_min=2.1E-03
RK2                  r: 2.3,  2.0, 2.0, 2.0 E_min=2.1E-03
MidpointIter         r: 2.0,  1.0, 2.0, 2.0 E_min=2.1E-03
</code></pre>
<!-- end verbatim block -->
The rates of the Forward and Backward Euler methods (1st and 3rd line) have
not yet converged to unity, as expected, while the 2nd-order
Runge-Kutta method, Leapfrog, and the \( \theta \) rule with
\( \theta =0.5 \)
(<code>ThetaRule</code> with default value of <code>theta</code>) shows the expected
\( r=2 \) value. The 4th-order Runge-Kutta holds the promise of being of 4th
order, while the filtered Leapfrog method has slow convergence and
a fairly large error, which is also evident in the previous figure.

<p>
Extending the time domain to 20 periods makes many of the
simplest methods inaccurate and the rates computed on coarse
time meshes are irrelevant. Also in this case, three of the methods
are useless, while the others deliver their promised convergence
rates (Forward Euler, i.e., <code>ThetaRule</code> with <code>theta=0</code> is left
out because of ridiculous results):
<!-- begin verbatim block  dat-->
<pre><code>LeapfrogFiltered     r: 63.7, 0.0, 0.1, 0.2 E_min=4.3E-01
ThetaRule(theta=1)   r: 0.0,  0.1, 0.1, 0.3 E_min=3.8E-01
ThetaRule            r: 3.7,  2.1, 2.0, 2.0 E_min=1.0E-02
RK4                  r: 4.0,  4.0, 4.0, 4.0 E_min=8.0E-07
Leapfrog             r: 0.5,  1.9, 2.0, 2.0 E_min=1.0E-02
RK2                  r: 3.7,  2.1, 2.0, 2.0 E_min=1.0E-02
MidpointIter         r: 1.8,  0.8, 1.9, 2.0 E_min=1.0E-02
</code></pre>
<!-- end verbatim block -->

<h1 id="___sec25">More Advanced Implementations </h1>

<h2 id="___sec26">Make a Subclass of Class Problem </h2>

<p>
Odespy features a module <code>problems</code> for defining ODE problems.
There is a superclass <code>Problem</code> in this module defining what we
expect of information about an ODE problem, as well as some
convenience functions that are inherited in subclasses.
A rough sketch of class <code>Problem</code> is listed here:
<!-- begin verbatim block  pycod-->
<pre><code>class Problem:
    stiff = False    # classification of the problem is stiff or not
    complex_ = False # True if f(u,t) is complex valued
    not_suitable_solvers = []  # list solvers that should be be used
    short_description = ''     # one-line problem description

    def __init__(self):
        pass

    def __contains__(self, attr):
        &quot;&quot;&quot;Return True if attr is a method in instance self.&quot;&quot;&quot;

    def terminate(self, u, t, step_number):
        &quot;&quot;&quot;Default terminate function, always returning False.&quot;&quot;&quot;
        return False

    def default_parameters(self):
        &quot;&quot;&quot;
        Compute suitable time_points, atol/rtol, etc. for the
        particular problem. Useful for quick generation of test
        cases, demos, unit tests, etc.
        &quot;&quot;&quot;
        return {}

    def u_exact(self, t):
        &quot;&quot;&quot;Implementation of the exact solution.&quot;&quot;&quot;
        return None
</code></pre>
<!-- end verbatim block -->
Subclasses of <code>Problem</code> typically implements the constructor, for
registering parameters in the ODE and the initial condition, and
a method <code>f</code> for defining the right-hand side. For implicit solution method
we may provide a method <code>jac</code> returning the Jacobian of \( f(u,t) \) with
respect to \( u \). Some problems may
also register an analytical solution in <code>u_exact</code>. Here is an
example of implementing the logistic ODE from the section <a href="#ode:sec:exgr">First Example: Logistic Growth</a>:
<!-- begin verbatim block  pycod-->
<pre><code>import odespy

class Logistic(odespy.problems.Problem):
    short_description = &quot;Logistic equation&quot;

    def __init__(self, a, R, A):
        self.a = a
        self.R = R
        self.U0 = A

    def f(self, u, t):
        a, R = self.a, self.R  # short form
        return a*u*(1 - u/R)

    def jac(self, u, t):
        a, R = self.a, self.R  # short form
        return a*(1 - u/R) + a*u*(1 - 1./R)

    def u_exact(self, t):
        a, R, U0 = self.a, self.R, self.U0  # short form
        return R*U0*numpy.exp(a*t)/(R + U0*(numpy.exp(a*t) - 1))
</code></pre>
<!-- end verbatim block -->
The <code>stiff</code>, <code>complex_</code>, and <code>not_suitable_solvers</code> class variables
can just be inherited. Note that <code>u_exact</code> should work for a vector <code>t</code>
so <code>numpy</code> versions of mathematical functions must be used.

<p>
The initial condition is by convention stored as the attribute <code>U0</code>
in a subclass of <code>Problem</code>, and specified as argument to the constructor.

<p>
Here are the typical steps when using such a problem class:
<!-- begin verbatim block  pycod-->
<pre><code>problem = Logistic(a=2, R=1E+5, A=1)
solver = odespy.RK4(problem.f)
solver.set_initial_condition(problem.U0)
u, t = solver.solve(time_points)
</code></pre>
<!-- end verbatim block -->

<p>
The problem class may also feature additional methods:
<!-- begin verbatim block  pycod-->
<pre><code>class MyProblem(odespy.problems.Problem)
    ...
    def constraints(self, u, t):
        &quot;&quot;&quot;Python function for additional constraints: g(u,t)=0.&quot;&quot;&quot;

    def define_command_line_arguments(self, parser):
        &quot;&quot;&quot;
        Initialize an argparse object for reading command-line
        option-value pairs. `parser` is an ``argparse`` object.
        &quot;&quot;&quot;

    def verify(self, u, t, atol=None, rtol=None):
        &quot;&quot;&quot;
        Return True if u at time points t coincides with an exact
        solution within the prescribed tolerances. If one of the
        tolerances is None, return max computed error (infinity
        norm). Return None if the solution cannot be verified.
        &quot;&quot;&quot;
</code></pre>
<!-- end verbatim block -->

<p>
The module <code>odespy.problems</code> contains many predefined ODE problems.

<h2 id="___sec27">Example: Solving a Complex ODE Problem </h2>

<p>
Many of the solvers offered by Odespy can deal with complex-valued
ODE problems. Consider

$$ u' = iwu,\quad u(0)=1,$$

where \( i=\sqrt{-1} \) is the imaginary unit.
The right-hand side is implemented as <code>1j*w*u</code> in Python since
Python applies <code>j</code> as the imaginary unit in complex numbers.

<h3 id="___sec28">Quick Implementation </h3>

<p>
For complex-valued ODEs, i.e., complex-valued right-hand side functions
or initial conditions, the argument <code>complex_valued=True</code> must be
supplied to the constructor. A complete program reads

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def f(u, t):
    return 1j*w*u

import odespy, numpy

w = 2*numpy.pi
solver = odespy.RK4(f, complex_valued=True)
solver.set_initial_condition(1+0j)
u, t = solver.solve(numpy.linspace(0, 6, 101))
</code></pre>
<!-- end verbatim block -->

<p>
The function <code>odespy.list_not_suitable_complex_solvers()</code>
returns a list of all the classes in Odespy that are not suitable
for complex-valued ODE problems.

<h3 id="___sec29">Comparison of Methods </h3>

<p>
We can try three classes that do work for complex-valued ODEs: <code>Vode</code>,
<code>RK4</code>, and <code>RKFehlberg</code>. Comparing these with respect to CPU time and
final error for a very long time integration of 600 periods is carried
out by the following program.

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def f(u, t):
    return 1j*w*u

import odespy, numpy, time

w = 2*numpy.pi
n = 600  # no of periods
r = 40   # resolution of each period
tp = numpy.linspace(0, n, n*r+1)

solvers = [odespy.Vode(f, complex_valued=True,
                       atol=1E-7, rtol=1E-6,
                       adams_or_bdf='adams'),
           odespy.RK4(f, complex_valued=True),
           odespy.RKFehlberg(f, complex_valued=True,
                             atol=1E-7, rtol=1E-6)]
cpu = []
for solver in solvers:
    solver.set_initial_condition(1+0j)
    t0 = time.clock()
    solver.solve(tp)
    t1 = time.clock()
    cpu.append(t1-t0)

# Compare solutions at the end point:
exact = numpy.exp(1j*w*tp).real[-1]
min_cpu = min(cpu); cpu = [c/min_cpu for c in cpu]  # normalize
print 'Exact: u(%g)=%g' % (tp[-1], exact)
for solver, cpu_time in zip(solvers, cpu):
    print '%-15s u(%g)=%.6f (error: %10.2E, cpu: %.1f)' % \ 
          (solver.__class__.__name__,
           solver.t[-1], solver.u[-1].real,
           exact - solver.u[-1].real, cpu_time)
</code></pre>
<!-- end verbatim block -->
We remark that the solution and the corresponding time values can always
be recovered as <code>solver.u</code> and <code>solver.t</code>, respectively.

<p>
The output from the program may read
<!-- begin verbatim block  dat-->
<pre><code>Exact: u(600)=1
Vode            u(600)=1.001587 (error:  -1.59E-03, cpu: 1.0)
RK4             u(600)=0.997328 (error:   2.67E-03, cpu: 1.3)
RKFehlberg      u(600)=1.000953 (error:  -9.53E-04, cpu: 7.5)
</code></pre>
<!-- end verbatim block -->
The <code>Vode</code> solver is a wrapper of the FORTRAN code <code>zvode.f</code> in
<code>scipy.integrate.ode</code> and is an adaptive Adams method (with default
settings, as used here),
<code>RK4</code> is a compact and straightforward Runge-Kutta method of order 4 in
pure Python with constant step size, and <code>RKFehlberg</code> is a pure Python
implementation of the adaptive Runge-Kutta-Fehlberg method of order
(4,5).  These methods give approximately the same final error, but
with different CPU times. We observe that the very simple <code>RK4</code> solver
in pure Python compares favorably with the much more sophisticated
FORTRAN subroutine <code>zvode</code>.

<h2 id="___sec30">Avoiding Callbacks to Python </h2>

<p>
The ODE solvers that are implemented in FORTRAN calls, by default,
the user's Python implementation of \( f(u,t) \). Making many calls from
FORTRAN to Python may introduce significant overhead and slow down the
solution process. When the algorithm is implemented in FORTRAN we should
also implement the right-hand side in FORTRAN and call this right-hand
side subroutine directly. Odespy offers this possibility.

<p>
The idea is that the user writes a FORTRAN subroutine defining \( f(u,t) \).
Thereafter, <code>f2py</code> is used to make this subroutine callable from Python.
If we specify the Python interface to this subroutine as an <code>f_f77</code>
argument to the solver's constructor, the Odespy class will make sure
that no callbacks to the \( f(u,t) \) definition go via Python.

<h3 id="___sec31">The Logistic ODE </h3>

<p>
Here is a minimalistic example involving the logistic ODE from
the section <a href="#ode:sec:exgr">First Example: Logistic Growth</a>. The FORTRAN implementation of \( f(u,t) \)
is more complicated than the Python counterpart. The subroutine
has the signature
<!-- begin verbatim block  fcod-->
<pre><code>      subroutine f_f77(neq, t, u, udot)
Cf2py intent(hide) neq
Cf2py intent(out) udot
      integer neq
      double precision t, u, udot
      dimension u(neq), udot(neq)
</code></pre>
<!-- end verbatim block -->
This means that there are two additional arguments: <code>neq</code> for the number
of equations in the ODE system, and <code>udot</code> for the array of \( f(u,t) \)
that is output from the subroutine.

<p>
We write the FORTRAN implementation of \( f(u,t) \) in a string:
<!-- begin verbatim block  pycod-->
<pre><code>a = 2
R = 1E+5

f_f77_str = &quot;&quot;&quot;
      subroutine f_f77(neq, t, u, udot)
Cf2py intent(hide) neq
Cf2py intent(out) udot
      integer neq
      double precision t, u, udot
      dimension u(neq), udot(neq)
      udot(1) = %.3f*u(1)*(1 - u(1)/%.1f)
      return
      end
&quot;&quot;&quot; % (a, R)
</code></pre>
<!-- end verbatim block -->
Observe that we can transfer problem parameters to the FORTRAN subroutine
by writing their values directly into the FORTRAN source code.
The other alternative would be to transfer the parameters as global
(COMMON block) variables to the FORTRAN code, which is technically
much more complicated.
Also observe that we need to deal with <code>udot</code> and <code>u</code> as arrays even
for a scalar ODE.

<p>
Using <code>f2py</code> to compile the string into a Python module is automated
by the <code>odespy.compile_f77</code> function:
<!-- begin verbatim block  pycod-->
<pre><code>import odespy
f_f77 = odespy.compile_f77(f_f77_str)
</code></pre>
<!-- end verbatim block -->
The returned object <code>f_f77</code> is a callable object that allows the
FORTRAN subroutine to be called as <code>udot = f_f77(t, u)</code> from Python.
(However, the Odespy solvers will not use <code>f_f77</code> directly, but rather
its function pointer to the FORTRAN subroutine, and transfer this pointer
to the FORTRAN solver. The switching between <code>t, u</code> and <code>u, t</code> arguments
is taken care of. All necessary steps are automatically done behind
the scene.)

<p>
The solver can be declared as
<!-- begin verbatim block  pycod-->
<pre><code>solver = odespy.Lsode(f=None, f_f77=f_f77)
</code></pre>
<!-- end verbatim block -->
Several solvers accept FORTRAN definitions of the right-hand side:
<code>Lsode</code>, <code>Lsoda</code>, and the other ODEPACK solvers, <code>RKC</code>, <code>RKF45</code>,
<code>Radau5</code>. Look up the documentation of their <code>f_f77</code> parameter to
see exactly what arguments and conventions that the FORTRAN subroutine
demand.

<p>
The file <a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/logistic10.py" target="_self"><tt>logistic10.py</tt></a> contains a complete program for solving the logistic ODE
with \( f(u,t) \) implemented in Fortran.

<h3 id="___sec32">Implementing the van der Pol Equation in FORTRAN </h3>

<p>
As a slightly more complicated example, also involving a subclass
of <code>Problem</code> and computation of the Jacobian and \( f(u,t) \) in
FORTRAN, we consider the van der Pol equation,
$$ y'' = \mu (1 - y^2) y' - y,\quad y(0)=2,\ y'(0)=1, $$

written as a system as shown in the section <a href="#ode:sec:motivation">Motivation</a>.
We start by implementing a problem class with Python code for
\( f(u,t) \) and its Jacobian:
<!-- begin verbatim block  pycod-->
<pre><code>import odespy

class VanDerPolOscillator(odespy.problems.Problem):
    short_description = &quot;Van der Pol oscillator&quot;

    def __init__(self, U0=[2, 1], mu=3.):
        self.U0 = U0
        self.mu = mu

    def f(self, u, t):
        u_0, u_1 = u
        mu = self.mu
        return [u_1, mu*(1 - u_0**2)*u_1 - u_0]

    def jac(self, u, t):
        u_0, u_1 = u
        mu = self.mu
        return [[0., 1.],
                [-2*mu*u_0*u_1 - 1, mu*(1 - u_0**2)]]
</code></pre>
<!-- end verbatim block -->

<p>
Now, we want to provide <code>f</code> and <code>jac</code> in FORTRAN as well.
The FORTRAN code for \( f(u,t) \) can be returned from a method:
<!-- begin verbatim block  pycod-->
<pre><code>class VanDerPolOscillator(odespy.problems.Problem):
    ...
    def str_f_f77(self):
        &quot;&quot;&quot;Return f(u,t) as Fortran source code string.&quot;&quot;&quot;
        return &quot;&quot;&quot;
      subroutine f_f77(neq, t, u, udot)
Cf2py intent(hide) neq
Cf2py intent(out) udot
      integer neq
      double precision t, u, udot
      dimension u(neq), udot(neq)
      udot(1) = u(2)
      udot(2) = %g*(1 - u(1)**2)*u(2) - u(1)
      return
      end
&quot;&quot;&quot; % self.mu
</code></pre>
<!-- end verbatim block -->

<p>
While all FORTRAN solvers supported by Odespy so far employ the same
signature for the \( f(u,t) \) function, different solvers apply different
signatures for the Jacobian. Here are two versions for ODEPACK and
<code>Radau5</code>, respectively:
<!-- begin verbatim block  pycod-->
<pre><code>class VanDerPolOscillator(odespy.problems.Problem):
    ...
    def str_jac_f77_fadau5(self):
        return &quot;&quot;&quot;
      subroutine jac_f77_radau5(neq,t,u,dfu,ldfu,rpar,ipar)
Cf2py intent(hide) neq,rpar,ipar
Cf2py intent(in)   t,u,ldfu
Cf2py intent(out) dfu
      integer neq,ipar,ldfu
      double precision t,u,dfu,rpar
      dimension u(neq),dfu(ldfu,neq),rpar(*),ipar(*)
      dfu(1,1) = 0
      dfu(1,2) = 1
      dfu(2,1) = -2*%g*u(1)*u(2) - 1
      dfu(2,2) = %g*(1-u(1)**2)
      return
      end
&quot;&quot;&quot; % (self.mu, self.mu)

    def str_jac_f77_lsode_dense(self):
        return &quot;&quot;&quot;
      subroutine jac_f77(neq, t, u, ml, mu, pd, nrowpd)
Cf2py intent(hide) neq, ml, mu, nrowpd
Cf2py intent(out) pd
      integer neq, ml, mu, nrowpd
      double precision t, u, pd
      dimension u(neq), pd(nrowpd,neq)
      pd(1,1) = 0
      pd(1,2) = 1
      pd(2,1) = -2*%g*u(1)*u(2) - 1
      pd(2,2) = %g*(1 - u(1)**2)
      return
      end
&quot;&quot;&quot; % (self.mu, self.mu)
</code></pre>
<!-- end verbatim block -->
For the <code>Lsode</code> solver we can also provide the Jacobian in banded matrix
format (this is not yet supported for <code>Radau5</code>, but the underlying
FORTRAN code allows a banded Jacobian).

<p>
Having some methods returning FORTRAN code, we need to turn
the source code into Python modules. This is done by
<code>odespy.compile_f77</code> in the constructor of class <code>VanDerPolOscillator</code>:
<!-- begin verbatim block  pycod-->
<pre><code>class VanDerPolOscillator(odespy.problems.Problem):

    def __init__(self, U0=[2, 1], mu=3.):
        self.U0 = U0
        self.mu = mu

        # Compile F77 functions
        self.f_f77, self.jac_f77_radau5, self.jac_f77_lsode = \ 
                    compile_f77([self.str_f_f77(),
                                 self.str_jac_f77_radau5(),
                                 self.str_jac_f77_lsode()])
</code></pre>
<!-- end verbatim block -->

<p>
The application of this problem class goes as follows:
<!-- begin verbatim block  pycod-->
<pre><code>problem = VanDerPolOscillator()
import odespy
solver = odespy.Radau5(f=None, f=problem.f_f77,
                       jac=problem.jac_f77_radau5)
solver.set_initial_condition(problem.U0)
u, t = solver.solve(time_points)
</code></pre>
<!-- end verbatim block -->

<h2 id="___sec33">Example: Solving a Stochastic Differential Equation </h2>

<p>
We consider an oscillator driven by stochastic white noise:
$$ x''(t) + bx'(t) + cx(t) = N(t),\ x(0)=X,\ x'(0) =0,$$

where \( N(t) \) is the white noise function computed numerically as
$$ N(t_i) \approx \sigma\frac{\Delta W_i}{\sqrt{t_{i+1}-t_i}},$$

where \( \Delta W_1,\Delta W_2,\ldots \) are independent normally
distributed random variables with mean zero and unit standard
deviation, and \( \sigma \) is the strength of the noise.  The physical
feature of this problem is that \( N(t) \) provides an excitation
containing "all" frequencies, but the oscillator is a strong filter:
with low damping one of the frequencies in \( N(t) \) will hit the
resonance frequency \( \sqrt{c}/(2\pi) \) which will then dominate the
output signal \( x(t) \).

<p>
The noise is additive in this stochastic differential equation so
there is no difference between the Ito and Stratonovich interpretations
of the equation.

<p>
The challenge with this model problem is that stochastic differential
equations do not fit with the user interface offered by Odespy,
since the right-hand side function is assumed to be dependent only
on the solution and the present time (<code>f(u,t)</code>), and additional
user-defined parameters, but for the present problem the right-hand
side function needs information about \( N(t) \) and hence
the size of the current time step.

<p>
We can solve this issue by having a reference to the solver in the
right-hand side function, precomputing \( N(t_i) \) for all time intervals
\( i \), and using the <code>n</code> attribute in the solver for selecting the right
force term (recall that some methods will call the right-hand side
function many times during a time interval - all these calls must use
the same value of the white noise).

<p>
The right-hand side function must do many things so a class is
appropriate:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>class WhiteNoiseOscillator:
    def __init__(self, b, c, sigma=1):
        self.b, self.c, self.sigma = b, c, sigma

    def connect_solver(self, solver):
        &quot;&quot;&quot;Solver is needed for time step number and size.&quot;&quot;&quot;
        self.solver = solver

    def f(self, u, t):
        if not hasattr(self, 'N'):  # is self.N not yet computed?
            # Compute N(t) for all time intervals
            import numpy
            numpy.random.seed(12)
            t = self.solver.t
            dW = numpy.random.normal(loc=0, scale=1, size=len(t)-1)
            dt = t[1:] - t[:-1]
            self.N = self.sigma*dW/numpy.sqrt(dt)

        x, v = u
        N = self.N[self.solver.n]
        return [v, N -self.b*v -self.c*x]
</code></pre>
<!-- end verbatim block -->
Note that \( N(t) \) is computed on demand the first time the right-hand side
function is called. We need to wait until the <code>f</code> method is called since
we need access to the solver instance to compute the <code>self.N</code> array.

<p>
It is easy to compare different methods for solving this stochastic equation:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>problem = WhiteNoiseOscillator(b=0.1, c=pi**2, sigma=1)
solvers = [odespy.Heun(problem.f), odespy.RK4(problem.f),
           odespy.ForwardEuler(problem.f)]
for solver in solvers:
    f.connect_solver(solver)
    solver.set_initial_condition([0,0])  # start from rest
    T = 60   # with c=pi**2, the period is 1
    u, t = solver.solve(linspace(0, T, 10001))

    x = u[:,0]
    plot(t, x)
    hold(True)

legend([str(s) for s in solvers])
</code></pre>
<!-- end verbatim block -->
All solutions are also stored in the solver objects
as attributes <code>u</code> and <code>t</code>, so we
may easily extract the solution of <code>RK4</code> by
<!-- begin verbatim block  pycod-->
<pre><code>solvers[1].u, solvers[1].t
</code></pre>
<!-- end verbatim block -->

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 5:  Oscillator driven by white noise. </p></center>
<p><img src="fig-odespy/sode1.png" align="bottom" width=500></p>
</center>

<p>
The <code>Heun</code> and <code>RK2</code> methods give coinciding solutions while
the <code>ForwardEuler</code> method gives too large amplitudes.
The frequency is 0.5 (period 2) as expected.

<p>
In this example the white noise force is computed only once since
the <code>f</code> instance is reused in all methods. If a new <code>f</code> is created
for each method, it is crucial that the same seed of the random
generator is used for all methods, so that the time evolution of
the force is always the same - otherwise the solutions will be
different.

<p>
The complete code is available in <a href="https://github.com/hplgit/odespy/blob/master/doc/src/tutorial/src-odespy/sode1.py" target="_self">sode.py</a>.

<h1 id="___sec34">Adaptive Methods </h1>

<p>
The solvers used in the previous examples have all employed a constant
time step \( \Delta t \). Many solvers available through the Odespy
interface are adaptive in the sense that \( \Delta t \) is adjusted
throughout the solution process to meet a prescribed tolerance for
the estimated error.

<p>
Simple methods such as <code>RK4</code> apply time steps
<!-- begin verbatim block  pycod-->
<pre><code>dt = time_points[k+1] - time_points[k]
</code></pre>
<!-- end verbatim block -->
while adaptive methods will use several (smaller) time steps than <code>dt</code>
in each <code>dt</code> interval to ensure that the estimated numerical error is
smaller than some prescribed tolerance. The estimated numerical error
may be a rather crude quantitative measure of the true numerical
error (which we do not know since the exact solution of the problem is
in general not known).

<p>
Some adaptive solvers record the intermediate solutions in each <code>dt</code>
interval in arrays <code>self.u_all</code> and <code>self.t_all</code>.  Examples include
<code>RKFehlberg</code>, <code>Fehlberg</code>, <code>DormandPrince</code>, <code>CashKarp</code>, and
<code>BogackiShampine</code>. Other adaptive solvers (<code>Vode</code>, <code>Lsode</code>, <code>Lsoda</code>,
<code>RKC</code>, <code>RKF45</code>, etc.)  do not give access to intermediate solution
steps between the user-given time points, specified in the
<code>solver.solve</code> call, and then we only have access to the solution at
the user-given time points as returned by this call. One can run <code>if
solver.has_u_t_all()</code> to test if the <code>solver.u_all</code> and <code>solver.t_all</code>
arrays are available.  These are of interest to see how the adaptive
strategy works between the user-specified time points.

<h2 id="___sec35">The Test Problem </h2>

<p>
We consider the ODE problem for testing adaptive solvers:

$$
\begin{equation}
u' = -\frac{t-c}{s^2} (u-1)
\label{gaussian:ode:eq}
\end{equation}
$$

The exact solution is a Gaussian function,
$$
u(t) = 1 + \exp{\left(-\frac{1}{2}\left(\frac{t-c}{s}\right)^2\right)}
$$

centered around \( t=c \) and width characteristic width ("standard
deviation") \( s \). The initial condition is taken as the exact \( u \) at \( t=0 \).

<p>
Since the Gaussian function is significantly different from zero only in the
interval \( [c-3s, c+3s] \), one may expect that adaptive methods will
efficiently take larger steps when \( u \) is almost constant and increase
the resolution when \( u \) changes substantially in the vicinity
of \( t=c \). We can test if this is the case with several solvers.

<h2 id="___sec36">Running Simple Methods </h2>

<p>
Let us first use a simple standard method like the 2nd- and 4th-order
Runge-Kutta methods with constant step size. With the former method
(<code>RK2</code>), \( c=3 \), \( s=0.5 \), and \( 41 \) uniformly distributed points,
the discrepancy between the numerical and exact solution in
Figure <a href="#gaussian:fig:RK2:41">6</a> is substantial. Increasing the number
of points by a factor of 10 gives a solution much closer to the
exact one, and switching to the 4th-order method (<code>RK4</code>) makes the
curves visually coincide. The problem is therefore quite straightforward
to solve using a sufficient number of points (400) and a higher-order method
such as <code>RK4</code>.
For curiosity we can mention that the <code>ForwardEuler</code> method produces
a maximum value of 0.98 with 20,000 points and 0.998 with 200,000 points.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 6:  2nd-order Runge-Kutta method with 41 points.  <div id="gaussian:fig:RK2:41"></div> </p></center>
<p><img src="fig-odespy/gaussian1_RK2_41.png" align="bottom" width=500></p>
</center>

<p>
A simple program testing one numerical method goes as follows (<a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/gaussian1.py" target="_self"><tt>gaussian1.py</tt></a>).

<p>
<!-- begin verbatim block  pypro-->
<pre><code>import odespy, numpy as np, matplotlib.pyplot as plt

center_point = 3
s = 0.5

problem = odespy.problems.Gaussian1(c=center_point, s=s)

npoints = 41
tp = np.linspace(0, 2*center_point, npoints)

method = odespy.RK2
solver = method(problem.f)
solver.set_initial_condition(problem.U0)

u, t = solver.solve(tp)

method = solver.__class__.__name__
print '%.4f  %s' % (u.max(), method)

if solver.has_u_t_all():
    plt.plot(solver.t_all, solver.u_all, 'bo',
             tp, problem.u_exact(tp))
    print '%s used %d steps (%d specified)' % \
          (method, len(solver.u_all), len(tp))
else:
    plt.plot(tp, solver.u, tp, problem.u_exact(tp))
plt.legend([method, 'exact'])
plt.savefig('tmppng'); plt.savefig('tmp.pdf')
plt.show()
</code></pre>
<!-- end verbatim block -->

<h2 id="___sec37">Running the Runge-Kutta-Fehlberg Method </h2>

<p>
One of the most widely used general-purpose, adaptive methods for
ODE problems is the
Runge-Kutta-Fehlberg method of order (4,5). This method is available
in three alternative implementations in Odespy: a direct Python
version (<code>RKFehlberg</code>), a specialization of a generalized
implementation of explicit adaptive Runge-Kutta methods
(<code>Fehlberg</code>), and as a FORTRAN code (<code>RKF45</code>). We can try one of
these,
<!-- begin verbatim block  pycod-->
<pre><code>method = odespy.Fehlberg
</code></pre>
<!-- end verbatim block -->
Figure <a href="#gaussian:fig:Fehlberg:41">7</a> shows how <code>Fehlberg</code> with 40 intervals produces a solution of reasonable accuracy. The dots show the actual computational points used by the algorithm (57 adaptively selected points in time).

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 7:  Adaptive Runge-Kutta-Fehlberg method with 57 points (starting with 41).  <div id="gaussian:fig:Fehlberg:41"></div> </p></center>
<p><img src="fig-odespy/gaussian1_Fehlberg_41.png" align="bottom" width=500></p>
</center>

<p>
Adaptive algorithms apply an error estimate based on considering a higher-order method as exact, in this case a method of order 5, and a method of lower order (here 4) as the numerically predicted solution. The user can specify an error tolerance. In the program above we just relied to the default tolerance, which can be printed by
<!-- begin verbatim block  pycod-->
<pre><code>print solver.get()
</code></pre>
<!-- end verbatim block -->
yielding a list of all optional parameters:
<!-- begin verbatim block  dat-->
<pre><code>{'f_kwargs': {}, 'f_args': (),
 'max_step': 1.5000000000000036, 'verbose': 0,
 'min_step': 0.0014999999999999946,
 'first_step': 0.14999999999999999,
 'rtol': 1e-06, 'atol': 1e-08,
 'name of f': 'f', 'complex_valued': False,
 'disk_storage': False, 'u_exact': None}
</code></pre>
<!-- end verbatim block -->
The tolerances involved are of relative and absolute type, i.e.,
<!-- begin verbatim block  pycod-->
<pre><code>estimated_error &lt;= tol = rtol*abs(u) + atol
</code></pre>
<!-- end verbatim block -->
is the typical test on whether the solution is sufficiently.
For very small <code>u</code>, <code>atol</code> comes into play, while for large <code>u</code>, the
relative tolerance <code>rtol</code> dominates.

<p>
In this particular example, running <code>RK4</code> with 57 equally spaced points
yields a maximum value of 1.95, while <code>Fehlberg</code> with 57 adaptively
selected points results in 1.98. Note that the tolerances used are
\( 10^{-6} \) while the real error is of the order \( 10^{-2} \).

<p>
We can specify stricter tolerances and also control the minimum
allowed step size, <code>min_step</code>, which might be too large to achieve
the desired error level (<a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/gaussian2.py" target="_self"><tt>gaussian2.py</tt></a>):

<p>
<!-- begin verbatim block  pycod-->
<pre><code>rtol = 1E-12
atol = rtol
min_step = 0.000001

solver = odespy.Fehlberg(problem.f, atol=atol, rtol=rtol,
                         min_step=min_step)
</code></pre>
<!-- end verbatim block -->

<p>
The <code>Fehlberg</code> solver now applies 701 points and achieves a maximum
value of 2.00005. However, <code>RK4</code> with the same number of (equally spaced) points
achieves the same accuracy and is much faster.

<h2 id="___sec38">Testing More Adaptive Solvers </h2>

<p>
We have already solved \eqref{gaussian:ode:eq} with sufficient accuracy, but
let us see how other methods perform, as this will most likely result in
a surprise. Below is a program (<a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/gaussian3.py" target="_self"><tt>gaussian3.py</tt></a>) that compares several famous and
widely used methods in the same plot.

<p>
<!-- begin verbatim block  pypro-->
<pre><code>import odespy, numpy as np, matplotlib.pyplot as plt

def run(problem, tp, solver):
    method = solver.__class__.__name__

    solver.set_initial_condition(problem.U0)

    u, t = solver.solve(tp)
    solver.u_max = u.max()
    print '%.4f  %s' % (solver.u_max, method)

    if solver.has_u_t_all():
        plt.plot(solver.t_all, solver.u_all)
        print '%s used %d steps (%d specified)' % \
              (method, len(solver.u_all), len(tp))
    else:
        plt.plot(solver.t, solver.u)
    legend.append(method)
    plt.hold('on')

rtol = 1E-6
atol = rtol
s = 0.5
npoints = 41
center_point = 3
problem = odespy.problems.Gaussian1(c=center_point, s=s)
tp = np.linspace(0, 2*center_point, npoints)
min_step = 0.0001

methods = ['DormandPrince', 'BogackiShampine',
           'RKFehlberg', 'Vode', 'RKF45', 'Lsoda']
solvers = [eval('odespy.' + method)(
           problem.f, atol=atol, rtol=rtol,
           min_step=min_step)
           for method in methods]
# Run Vode with implicit BDF method of order 5
solvers[1].set(adams_or_bdf='bdf', order=5, jac=problem.jac)

legend = []
for solver in solvers:
    run(problem, tp, solver)

plt.plot(tp, problem.u_exact(tp))
legend.append('exact')
plt.legend(legend)
plt.savefig('tmp1.png')

# Plot errors
plt.figure()
exact = problem.u_exact(tp)
for solver in solvers:
    plt.plot(tp, exact - solver.u)
    plt.hold('on')
plt.legend(legend)
plt.savefig('tmp2.png')
plt.show()
</code></pre>
<!-- end verbatim block -->

<p>
The default discretization applies \( N=40 \) equal-sized time intervals,
but adaptive methods should be able to adjust themselves to the
desired error level \( 10^{-6} \). Figures <a href="#gaussian3:fig1:41">8</a> and
<a href="#gaussian3:fig1err:41">9</a> show that this expected behavior is not the
case. There is substantial discrepancy between the methods!
Surprisingly, the well-known FORTRAN codes accessed by the <code>Vode</code>
(<code>vode.f</code>) and <code>Lsoda</code> (from ODEPACK) methods give very inaccurate
results, despite setting <code>Vode</code> to use a stiff BDF solver of order 5, and
<code>Lsoda</code> should automatically select between nonstiff and stiff solvers
(of default order 4 in this case).

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 8:  Comparison of adaptive methods with default parameters (tolerance <code>E-6</code>).  <div id="gaussian3:fig1:41"></div> </p></center>
<p><img src="fig-odespy/gaussian3_41.png" align="bottom" width=500></p>
</center>

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 9:  Comparison of errors in adaptive methods with default parameters (tolerance <code>E-6</code>).  <div id="gaussian3:fig1err:41"></div> </p></center>
<p><img src="fig-odespy/gaussian3e_41.png" align="bottom" width=500></p>
</center>

<p>
The program writes out the following results for the
maximum value of the solution, which should equal 2:
<!-- begin verbatim block  dat-->
<pre><code>1.9976  DormandPrince
1.6591  BogackiShampine
1.9812  RKFehlberg
1.0406  Vode
1.9734  RKF45
3.2905  Lsoda
</code></pre>
<!-- end verbatim block -->
The clearly most accurate solver among these is <code>DormandPrince</code>  - the default
method used by MATLAB's <code>ode45</code> solver, which is perhaps the world's
most popular ODE solver.

<p>
The remedy to get all the tested solvers to perform well is to
choose a much stricter tolerance, say \( 10^{-10} \).
Figure <a href="#gaussian3:fig2:41">10</a> shows
coinciding curves. Numerically, we now have
<!-- begin verbatim block  dat-->
<pre><code>1.9991  DormandPrince
1.9912  BogackiShampine
1.9942  RKFehlberg
2.0122  Vode
1.9916  RKF45
2.0056  Lsoda
</code></pre>
<!-- end verbatim block -->
For the methods <code>DormandPrince</code>,  <code>RKFehlberg</code>, and
<code>BogackiShampine</code> we have information about the number of adaptive
time points used: 270, 326, and 3307, respectively.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 10:  Comparison of adaptive methods with error tolerance <code>E-10</code>.  <div id="gaussian3:fig2:41"></div> </p></center>
<p><img src="fig-odespy/gaussian3_41_Em10.png" align="bottom" width=500></p>
</center>

<p>
The lesson learned in this example is two-fold: 1) several methods should
be tested to gain reliability of the results, and Odespy makes such tests
easy to conduct, and 2) strict tolerances, far below
the default values, may be necessary for some methods, here <code>Vode</code> and
<code>Lsoda</code> in particular. We remark that it is the ODE problem that causes
difficulties: changing the problem to <code>odespy.problems.Logistic</code>
(see the file <a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/logistic9.py" target="_self"><tt>logistic9.py</tt></a>)
shows that all the curves coincide and cannot be distinguished visually.

<p>
The present test problem with a Gaussian function as solution
can be made increasingly more difficult by
increasing the value of \( c/s \), i.e., a more peaked function moved to
the right.

<h2 id="___sec39">Extensive Testing </h2>

<p>
The program <a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/gaussian4.py" target="_self"><tt>gaussian4.py</tt></a>
sets up an extensive experiments involving a lot of solvers, several
\( c/s \) values, and several error tolerances.  The experiments clearly
demonstrate how challenging this ODE problem is for many adaptive
solvers unless \( c/s \) is moderate and a strict tolerance (much lower
than the real accuracy level) is used. One can especially see the
fundamental difficulties that <code>Vode</code>, <code>Lsode</code>, and <code>Lsoda</code> (all stiff
and nonstiff versions) face when \( c/s\geq 8 \): these solvers do not
manage to pick up any variation in \( u \). Nevertheless, for less
demanding ODEs these solvers may perform very well, but it is highly
recommended to always use the power of the unified Odespy interface
to test several different adaptive methods.

<h1 id="___sec40">Solving Partial Differential Equations </h1>

<p>
Let us now turn the attention to the method of lines for
partial differential equations  (PDEs) where one reduces a PDE to
a system of ODE and then applies standard methods ODEs.

<p>
We address a diffusion problem in one dimension:

$$
\begin{align}
\frac{\partial u(x,t)}{\partial t} &= \beta \frac{\partial^{2}u(x,t)}{\partial x^2} + f(x,t), &x \in \left(0,L\right), & t \in (0,T],
\label{odespy:pde:diffusion}  \\ 
u(0,t) &= s(t), & t \in (0,T],
\label{odespy:pde:diffusion:x0}  \\ 
\frac{\partial}{\partial x}u(L,t) &= 0, &t \in (0,T],
\label{odespy:pde:diffusion:xL}  \\ 
u(x,0) &= I(x), &x \in \left[0,L\right]
\label{odespy:pde:diffusion:I}
\thinspace .
\end{align}
$$

<h2 id="___sec41">Discretization in Space </h2>

<p>
Discretizing the 2nd-order derivative in space with a finite difference,
on a mesh \( x_i=i\Delta x \), \( i=1,\ldots,N-1 \), gives the ODEs

$$
\begin{equation}
\frac{\partial u_i(t)}{\partial t} = \beta
\frac{u_{i+1}(t) - 2u_i(t) + u_{i-1}(t)}{\Delta x^2} + f_i(t),\quad i=1,\ldots,N-1
\thinspace .
\end{equation}
$$

Here we have introduced the notation \( u_i(t) \) as an approximation to the
exact solution at mesh point \( x_i \).

<p>
The boundary condition on \( x=0 \), \( u(0,t)=s(t) \), gives rise to the ODE

$$ u_0'(t) = s'(t),\quad u_0(0)=s(0)\thinspace .$$

At the other end, \( x=L \), we use a centered difference approximation
\( (u_{N+1}(t)-u_{N-1}(t))/(2\Delta x) =0 \) and combine it with the
scheme for \( i=N \) to obtain the modified boundary ODE

$$
\begin{equation}
\frac{\partial u_N(t)}{\partial t} = \beta
\frac{2u_{N-1}(t) - 2u_N(t)}{\partial x^2} + f_N(t)\thinspace .
\end{equation}
$$

<p>
To summarize, the ODE system reads

$$
\begin{align}
\frac{du_0}{dt} &= s'(t),
\label{sec:pde:diff1D:ode1:0}\\ 
\frac{du_i}{dt} &=  \frac{\beta}{\Delta x^2}
(u_{i+1}(t) - 2u_i(t) + u_{i-1}(t)) + f_i(t),\quad i=1,\ldots,N-1,
\label{sec:pde:diff1D:ode1:i}\\ 
\frac{du_N}{dt} &=  \frac{2\beta}{\Delta x^2}
(u_{N-1}(t) - u_N(t)) + f_i(t)\thinspace .
\label{sec:pde:diff1D:ode1:N}
\end{align}
$$

The initial conditions are

$$
\begin{align}
u_0(0) &= s(0),\\ 
u_i(0) &= I(x_i),\quad i=1,\ldots,N\thinspace .
\end{align}
$$

We can apply any method for systems of ODEs to solve
\eqref{sec:pde:diff1D:ode1:0}-\eqref{sec:pde:diff1D:ode1:N}.

<h2 id="___sec42">Implementation </h2>

<p>
Consider
the evolution of the temperature in a rod modeled by our diffusion problem.
At \( t=0 \), the rod has the temperature 10 C. We then apply a heat source
at \( x=0 \) which keepes the temperature there at 50 C. This means that
\( I(x)=283 \) K, except at the end point:
\( I(0)=423 \) K, \( s(t) = 423 \) K, and \( f=0 \).

<p>
Odespy solvers need the right-hand side function of
\eqref{sec:pde:diff1D:ode1:0}-\eqref{sec:pde:diff1D:ode1:N}:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def rhs(u, t, L=None, beta=None, x=None):
    N = len(u) - 1
    dx = x[1] - x[0]
    rhs = zeros(N+1)
    rhs[0] = dsdt(t)
    for i in range(1, N):
        rhs[i] = (beta/dx**2)*(u[i+1] - 2*u[i] + u[i-1]) + \ 
                 f(x[i], t)
    rhs[N] = (beta/dx**2)*(2*u[i-1] - 2*u[i]) + f(x[N], t)
    return rhs
</code></pre>
<!-- end verbatim block -->
This function requires the variables <code>beta</code>, <code>x</code>, <code>dx</code>, and <code>L</code>, which
we provide as keyword arguments and that can be transferred to <code>rhs</code>
through the <code>f_kwargs</code> argument to the Odespy constructors.

<p>
We also need some helper functions

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def s(t):
    return 423

def dsdt(t):
    return 0

def f(x, t):
    return 0
</code></pre>
<!-- end verbatim block -->
Parameters and initial conditions can be set as

<p>
<!-- begin verbatim block  pycod-->
<pre><code>N = 40
L = 1
x = linspace(0, L, N+1)
f_kwargs = dict(L=L, beta=1, x=x)
u = zeros(N+1)

U_0 = zeros(N+1)
U_0[0] = s(0)
U_0[1:] = 283
</code></pre>
<!-- end verbatim block -->

<p>
The construction and execution of a solver is now a matter of

<p>
<!-- begin verbatim block  pycod-->
<pre><code>import odespy
solver = odespy.ForwardEuler(rhs, f_kwargs=f_kwargs)
solver.set_initial_condition(U_0)

dx = x[1] - x[0]
dt = dx**2/(2*beta) # Forward Euler limit
N_t = int(round(T/float(dt)))
time_points = linspace(0, T, N_t+1)

u, t = solver.solve(time_points)
</code></pre>
<!-- end verbatim block -->

<p>
We can add some flexibility and set up several solvers, also
implicit methods:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>import odespy
solvers = {
    'FE': odespy.ForwardEuler(
        rhs, f_kwargs=f_kwargs),
    'BE': odespy.BackwardEuler(
        rhs, f_is_linear=True, jac=K,
        f_kwargs=f_kwargs, jac_kwargs=f_kwargs),
    'B2': odespy.Backward2Step(
        rhs, f_is_linear=True, jac=K,
        f_kwargs=f_kwargs, jac_kwargs=f_kwargs),
    'theta': odespy.ThetaRule(
        rhs, f_is_linear=True, jac=K, theta=0.5,
        f_kwargs=f_kwargs, jac_kwargs=f_kwargs),
    'RKF': odespy.RKFehlberg(
        rhs, rtol=1E-6, atol=1E-8, f_kwargs=f_kwargs),
    'RKC': odespy.RKC(
        rhs, rtol=1E-6, atol=1E-8, f_kwargs=f_kwargs,
        jac_constant=True),
    }

try:
    method = sys.argv[1]
    dt = float(sys.argv[2])
    T = float(sys.argv[3])
except IndexError:
    method = 'FE'
    dx = x[1] - x[0]
    dt = dx**2/(2*beta) # Forward Euler limit
    print 'Forward Euler stability limit:', dt
    T = 1.2

solver = solvers[method]
</code></pre>
<!-- end verbatim block -->

<p>
The implicit solvers need the Jacobian of the right-hand side function:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def K(u, t, L=None, beta=None, x=None):
    N = len(u) - 1
    dx = x[1] - x[0]
    K = zeros((N+1,N+1))
    K[0,0] = 0
    for i in range(1, N):
        K[i,i-1] = beta/dx**2
        K[i,i] = -2*beta/dx**2
        K[i,i+1] = beta/dx**2
    K[N,N-1] = (beta/dx**2)*2
    K[N,N] = (beta/dx**2)*(-2)
    return K
</code></pre>
<!-- end verbatim block -->
Note that we work with <em>dense square matrices</em> while the mathematics
allows a tridiagonal matrix and corresponding solver.
However, in 1D problems, the computations
are so fast anyway so we can live with dense matrices.

<p>
Finally, some animation of the solution is desirable:

<p>
<!-- begin verbatim block  pycod-->
<pre><code># Make movie
import os
os.system('rm tmp_*.png')  # remove old plot files
plt.figure()
plt.ion()
y = u[0,:]
lines = plt.plot(x, y)
plt.axis([x[0], x[-1], 273, 1.2*s(0)])
plt.xlabel('x')
plt.ylabel('u(x,t)')
counter = 0
for i in range(0, u.shape[0]):
    print t[i]
    lines[0].set_ydata(u[i,:])
    plt.legend(['t=%.3f' % t[i]])
    plt.draw()
    if i % 5 == 0: # plot every 5 steps
        plt.savefig('tmp_%04d.png' % counter)
        counter += 1
    #time.sleep(0.2)
</code></pre>
<!-- end verbatim block -->

<h3 id="___sec43">Vectorized Code </h3>

<p>
It is easy to get rid of the loops in the <code>rhs</code> and <code>K</code> functions:

<p>
<!-- begin verbatim block  pycod-->
<pre><code>def rhs_vec(u, t, L=None, beta=None, x=None):
    N = len(u) - 1
    dx = x[1] - x[0]
    rhs = zeros(N+1)
    rhs[0] = dsdt(t)
    rhs[1:N] = (beta/dx**2)*(u[2:N+1] - 2*u[1:N] + u[0:N-1]) + \ 
               f(x[1:N], t)
    i = N
    rhs[i] = (beta/dx**2)*(2*u[i-1] - 2*u[i]) + f(x[N], t)
    return rhs

def K_vec(u, t, L=None, beta=None, x=None):
    &quot;&quot;&quot;Vectorized computation of K.&quot;&quot;&quot;
    N = len(u) - 1
    dx = x[1] - x[0]
    K = zeros((N+1,N+1))
    K[0,0] = 0
    K[1:N-1] = beta/dx**2
    K[1:N] = -2*beta/dx**2
    K[2:N+1] = beta/dx**2
    K[N,N-1] = (beta/dx**2)*2
    K[N,N] = (beta/dx**2)*(-2)
    return K
</code></pre>
<!-- end verbatim block -->

<h2 id="___sec44">Experiments </h2>

<p>
The program, <a href="https://github.com/hplgit/odespy/blob/master/doc/src/odespy/src-odespy/pde_diffusion.py" target="_self"><tt>pde_diffusion.py</tt></a>, can be run to test different solvers and illustrate numerical
methods:

<p>
<!-- Note: the "Run" after the paragraph, before code, is essential for -->
<!-- latex to produce correct code (a latex, not a doconce, problem). -->

<p>
<b>Forward Euler Method.</b>
Run

<p>
<!-- begin verbatim block  sys-->
<pre><code>python pde_diffusion.py
</code></pre>
<!-- end verbatim block -->
The graphics takes very long time in this simulation, because of the
small time step.

<p>
<b>Backward Euler.</b>
Run

<p>
<!-- begin verbatim block  sys-->
<pre><code>python ode_diffusion.py BE 0.05 1.2
</code></pre>
<!-- end verbatim block -->

<p>
<b>Backward 2-step Method.</b>
Run

<p>
<!-- begin verbatim block  sys-->
<pre><code>python ode_diffusion.py B2 0.05 1.2
</code></pre>
<!-- end verbatim block -->

<p>
<b>Crank-Nicolson Method.</b>
Run

<p>
<!-- begin verbatim block  sys-->
<pre><code>python ode_diffusion.py theta 0.01 1.2
</code></pre>
<!-- end verbatim block -->
Observe the non-physical oscillations because of the steep initial
condition (and the lack of damping in the Crank-Nicolson scheme).

<p>
<b>Runge-Kutta-Fehlberg Method.</b>
Run

<p>
<!-- begin verbatim block  sys-->
<pre><code>python ode_diffusion.py RKF 0.01 1.2
</code></pre>
<!-- end verbatim block -->
Note here that we specify a quite large \( \Delta t \), much larger than
what a Runge-Kutta method can work with (typically, an RK4 method
needs a \( \Delta t \) as small as the critical step for the Forward Euler
method). However, the adaptive method figures out what it needs of
steps and produces a nice solution.

<p>
<b>Runge-Kutta-Chebyshev Method.</b>
Run

<p>
<!-- begin verbatim block  sys-->
<pre><code>python ode_diffusion.py RKC 0.05 1.2
</code></pre>
<!-- end verbatim block -->
This is a promising method for the diffusion equation. It works like
an explicit method and can tolerate large time steps. This method calls
up the FORTRAN code <code>rkc.f</code>.

<h1 id="___sec45">Inner Workings of the Package </h1>

<p>
There are three basic entities when solving ODEs numerically: the
definition of the <em>ODE system</em>, the <em>time-stepping method</em>, and
the <em>solver</em> that runs the "time loop" and stores results.

<p>
The information about the ODE system is made very simple: the user
provides 1) an object that can be called as a Python function <code>f(u,
t)</code>, and 2) an array or list with the initial values.  Some users will
store this information in their own data structures, e.g., a class.

<p>
The time-stepping method and the algorithm for calling the time-stepping
are collected in a solver class. All the solver classes are
related in a class hierarchy. Each solver class initialized by the right-hand
side function (<code>f</code>) and an optional set of parameters for controlling
various parts of the solution process. The solver object is also
used to set the initial condition (<code>set_initial_condition</code>) and
to run the solution process (<code>solve</code>). The time-stepping scheme
is normally isolated in a method <code>advance</code> in the solver classes, but
for some schemes or external software packages the separation of
doing one step and doing the whole time integration is less feasible.
In those cases, <code>solve</code> will mix the time-stepping loop and the
numerical scheme.

<p>
The package does not interact with visualization tools - the array
containing the solution is returned to the user and must be further
processed and visualized in the user's code.

<p>
Below we describe how the classes in the solver hierarchy work and how
parameters are registered and initialized.

<h2 id="odes:parameters">Solver Parameters</h2>

<p>
The <code>solver</code> module defines a global dictionary <code>_parameters</code> holding
all legal parameters in Odespy classes. These are parameters that
the user can adjust. Other modules imports this <code>_parameters</code> dict
and updates it with their own additional parameters.

<p>
For each parameter the <code>_parameters</code> dict stores the parameter name, a
default value, a description, the legal object type for the value of
the parameter, and other quantities if needed. A typical example
is
<!-- begin verbatim block -->
<pre><code>_parameters = dict(
...

f = dict(
    help='Right-hand side f(u,t) defining the ODE',
    type=callable),

f_kwargs = dict(
    help='Extra keyword arguments to f: f(u, t, *f_args, **f_kwargs)',
    type=dict,
    default={}),

theta = dict(
    help='eight in [0,1] used for'\ 
         '&quot;theta-rule&quot; finite difference approx.',
    default=0.5,
    type=(int,float),
    range=[0, 1])

...
}
</code></pre>
<!-- end verbatim block -->

<p>
Each solver class defines a (static) class variable
<code>_required_parameters</code> for holding the names of all required
parameters (in a list). In addition, each solver class defines another
class variable <code>_optional_parameters</code> holding the names of all the
optional parameters. The doc strings of the solver classes are
automatically equipped with tables of required and optional
parameters.

<p>
The optional parameters of a class consist of the optional parameters
of the superclass and those specific to the class. The typical
initialization of <code>_optional_parameters</code> goes like this:
<!-- begin verbatim block  pycod-->
<pre><code>class SomeMethod(ParentMethod):
    _optional_parameters = ParentMethod._optional_parameters + \ 
                           ['prm1', 'prm2', ...]
</code></pre>
<!-- end verbatim block -->
where <code>prm1</code>, <code>prm2</code>, etc. are names registered in the global
<code>_parameters</code> dictionary.

<p>
From a user's point of view, the parameters are set either at
construction time or through the <code>set</code> function:
<!-- begin verbatim block  pyshell-->
<pre><code>&gt;&gt;&gt; from odespy import RK2
&gt;&gt;&gt; def f(u, t, a, b=0):
...   return a*u + b
...
&gt;&gt;&gt; solver = RK2(f, f_kwargs=dict(b=1))
&gt;&gt;&gt; solver.f_kwargs
{'b': 1}
&gt;&gt;&gt; solver.set(f_args=(3,))
&gt;&gt;&gt; solver.f_args
(3,)
&gt;&gt;&gt; # Get all registered parameters in the method instance
&gt;&gt;&gt; solver.get()
{'f_kwargs': {'b': 1}, 'f_args': (3,), 'complex_valued': False,
'name of f': 'f'}
</code></pre>
<!-- end verbatim block -->
The <code>set</code> method sets parameters through keyword arguments and can
take an arbitrary collection of such arguments:
<!-- begin verbatim block  pycod-->
<pre><code>solver.set(name1=value1, name2=value2, name3=value3, ...)
</code></pre>
<!-- end verbatim block -->

<p>
The <code>get</code> method returns the parameters and their values as a dictionary.
We remark that the <code>'f'</code> key, which one might expect to appear in the
returned dictionary of parameters, are omitted because it is always
a lambda function wrapping the user's <code>f</code> function such that the
returned value is guaranteed to be a <code>numpy</code> array. Instead,
there is an entry <code>'name of f'</code> which reflects the name of the
user-supplied function. The same comment applies to the <code>jac</code> parameter
for specifying the Jacobian used in implicit methods.

<h2 id="___sec47">Solver Classes </h2>

<p>
Each solver in this package is implemented as a class in a class hierarchy.
Basic, common functionality is inherited from super classes, and the
actual solver class implements what is specific for the method in question.

<h3 id="___sec48">The Inherited Superclass Constructor </h3>

<p>
Class <code>Solver</code> is the super class of the hierarchy. Subclasses
normally just inherit their constructor from class <code>Solver</code>. This
constructor requires one mandatory argument: the right-hand side of
the ODE, \( f(u,t) \), coded as a Python function <code>f(u, t)</code>.
Some solvers implemented in FORTRAN allows <code>f</code> to be a wrapper of
a FORTRAN function defining the right-hand side, but such a wrapper
is specified through the <code>f_f77</code> argument and using <code>None</code> for <code>f</code>.
The constructor accepts a range of
additional keyword arguments for setting
parameters of the solver. Which keyword arguments that are
available depends on what the subclass has registered as legal
parameters in <code>_optional_parameters</code> and <code>_required_parameters</code>.

<p>
The constructor performs a set of tasks that are common to all
the subclass solvers:

<ol>
<li> The set of optional and required parameters of a particular solver
   is loaded into <code>self._parameters</code> such that this dictionary
   can be used to look up all parameters of the solver.</li>
<li> The solver-specific method <code>adjust_parameters</code> is called to allow
   the programmer of a solver to manipulate <code>self._parameters</code>.
   For example, some parameters may be modified or set
   according to the value of others.</li>
<li> Entries in <code>self._parameters</code> are mirrored by class
   attributes. The computations and the <code>set</code> and <code>get</code> methods will
   make use of the attributes rather than the <code>self._parameters</code> dict
   to extract data.  For example, the value of
   <code>self._parameters['myvar']</code> becomes available as <code>self.myvar</code> and
   in the algorithms we use <code>self.myvar</code>, perhaps with a test
   <code>hasattr(self, 'myvar')</code> or a <code>try-except</code> clause (catching
   an <code>AttributeError</code>).</li>
<li> The <code>set</code> method is called with all keyword arguments given to the
   constructor, which then modifies the default values of the
   parameters and sets the corresponding attributes.</li>
<li> The <code>f</code> function is wrapped in a lambda function such that
   <code>f(u, t)</code> is guaranteed to return an array (in case the user
   returns a list or scalar for convenience). The same is done with
   the Jacobian (<code>jac</code>) and other user-defined callback functions.</li>
<li> The <code>initialize</code> method is called to finalize the tasks in
   the constructor. The most common use of this method in subclasses
   is to import extension modules that the solver depends on and
   provide an error message if the extension modules are not available.
   If they are, the modules are normally stored through an attribute
   of the subclass.</li>
</ol>

<h3 id="___sec49">Useful Methods </h3>

<p>
Let <code>solver</code> be some instance of a subclass in the hierarchy. The
following methods are sometimes useful:

<ul>
 <li> <code>repr(solver)</code>: return the subclass name along with all
   registered parameters and their values. This string provides
   complete information on the initialization of a solver.</li>
 <li> <code>str(solver)</code>: return a short pretty print string reflecting
   the name of the method and the value of parameters that
   must be known to uniquely define the numerical method.
   This string, or the class name as given by <code>solver.name()</code>,
   is useful for the legend in a plot or as method identifier in a table.</li>
 <li> <code>solver.get_parameter_info()</code>: return or print all registered
   parameters for the current solver and all properties for
   each parameter.</li>
<li> <code>solver.switch_to(name)</code>: return a new solver of type <code>name</code>,
   initialized with all
   parameters of the current solver that are legal in the new solver.
   The method is useful when trying out a range of solvers for a
   problem.</li>
</ul>

<h3 id="___sec50">The Solve Method </h3>

<p>
After the constructor is called, <code>solver.set_initial_condition</code> is
called to set the initial condition, and then <code>solve</code> is called.
The <code>solve</code> method features the following steps:

<ol>
<li> Call <code>initialize_for_solve</code> (implemented in subclasses) to
   precompute whatever is needed before the time loop.
   The super class allocates storage for the solution and
   loads the initial condition into that data structure.
   Any subclass implementation of <code>initialize_for_solve</code> must therefore
   also call this method in its super class.</li>
<li> Call <code>validate_data</code> to check if the data structures are consistent
   before starting the computations. Subclass implementations of
   this method must call the super class' version of the method.</li>
<li> Run a loop over all time levels <code>n</code> and call <code>advance</code> (implemented
   in subclasses) at each level to advance the solution from
   time <code>t[n]</code> to <code>t[n+1]</code>. Also call <code>terminate</code> so that the
   user code can analyze, work with the solution, and terminate the
   solution process.</li>
</ol>

Some subclasses will override the <code>solve</code> method and provide their own,
but most subclasses just inherits the general one and implements
the <code>advance</code> method.

<h3 id="___sec51">Solver Attributes </h3>

<p>
All classes have a set of attributes:

<ol>
<li> <code>users_f</code>: holds the user's function for \( f(u, t) \).
   Implicit solvers may have a corresponding <code>users_jac</code> for
   the user's Jacobian.</li>
<li> One attribute for each parameter in the class.</li>
<li> <code>u</code>: 1D <code>numpy</code> array holding the solution for a scalar ODE and
   a 2D array in case of a system of ODEs. The first index
   denotes the time level.</li>
<li> <code>t</code>: the time levels corresponding to the first index in the <code>u</code> array.</li>
<li> <code>quick_description</code>: a short one-line description of the method (this
   variable is static in the class, i.e., declared outside any method).</li>
</ol>

Most classes will also define two additional static variables,
<code>_required_parameters</code> and <code>_optional_parameters</code> as explained
in the section <a href="#odes:parameters">Solver Parameters</a>.

<h3 id="___sec52">Other Superclasses </h3>

<p>
There are superclasses <code>SolverImplicit</code> for implicit methods,
<code>Adaptive</code> for adaptive methods, <code>RungeKutta1level</code> for general,
explicit 1-level Runge-Kutta methods, <code>RungeKutta2level</code> for
general, explicit, adaptive 2-level Runge-Kutta methods,
<code>ode_scipy</code> for interfaces to ODE solvers
in <code>scipy</code>, and <code>Odepack</code> for interfaces to the ODEPACK family
of solvers.

<h2 id="___sec53">A Very Simple Subclass </h2>

<p>
To implement a simple explicit scheme for solving a scalar ODE or a system
of ODEs, you only need to write a subclass of <code>Solver</code> with an
<code>advance</code> method containing the formula that updates the solution from
one time level to the next. For example, the Forward Euler scheme
reads
$$ u_{n+1} = u_n + \Delta t f(u_n, t_n),$$

where subscript \( n \) denotes the time level, and \( \Delta t = t_{n+1}-t_n \) is
the current time step.
The implementation goes like
<!-- begin verbatim block  cod-->
<pre><code>class ForwardEuler(Solver):
    &quot;&quot;&quot;
    Forward Euler scheme::

        u[n+1] = u[n] + dt*f(u[n], t[n])
    &quot;&quot;&quot;
    quick_description = 'The simple explicit (forward) Euler scheme'

    def advance(self):
        u, f, n, t = self.u, self.f, self.n, self.t
        dt = t[n+1] - t[n]
        unew = u[n] + dt*f(u[n], t[n])
        return unew
</code></pre>
<!-- end verbatim block -->
Remarks:

<ol>
<li> The <code>quick_description</code> string is necessary for the class to appear in the
   automatically generated overview of implemented methods
   (run <code>pydoc odespy</code> to see this table).</li>
<li> Extracting class attributes in local variables (here <code>u</code>, <code>f</code>, etc.)
   avoids the need for the <code>self</code> prefix so that the implemented formulas
   are as close to the mathematical formulas as possible.</li>
</ol>

Almost equally simple schemes, like explicit Runge-Kutta methods and Heun's
method are implemented in the same way (see <a href="https://github.com/hplgit/odespy/tree/master/odespy/odespy/solvers.py" target="_self"><tt>solvers.py</tt></a>).

<h2 id="___sec54">A Subclass with More Code </h2>

<p>
A 2nd-order Adams-Bashforth scheme is a bit more complicated since it
involves three time levels and therefore needs a separate method for
the first step. We should also avoid unnecessary evaluations of \( f(u,t) \).
The user can specify a parameter <code>start_method</code> for the name of the
solver to be used for the first step. This solver is initialized
by the <code>switch_to</code> method in class <code>Solver</code>. Basically,
<!-- begin verbatim block  pycod-->
<pre><code>new_solver = solver.switch_to(solver_name)
</code></pre>
<!-- end verbatim block -->
creates a new solver instance <code>new_solver</code>, of the class implied by
<code>solver_name</code>, where all relevant parameters from <code>solver</code> are copied
to <code>new_solver</code>.

<p>
An implementation of a subclass for the
2nd-order Adams-Bashforth scheme can then look as follows.
<!-- begin verbatim block  pycod-->
<pre><code>class AdamsBashforth2(Solver):
    &quot;&quot;&quot;
    Second-order Adams-Bashforth method::

        u[n+1] = u[n] + dt/2.*(3*f(u[n], t[n]) - f(u[n-1], t[n-1]))

    for constant time step dt.

    RK2 is used as default solver in first step.
    &quot;&quot;&quot;
    quick_description = &quot;Explicit 2nd-order Adams-Bashforth method&quot;

    _optional_parameters = Solver._optional_parameters + \ 
                          ['start_method',]

    def initialize_for_solve(self):
        # New solver instance for first step
        self.starter = self.switch_to(self.start_method)
        Solver.initialize_for_solve(self)

    def validate_data(self):
        if not self.constant_time_step():
            print '%s must have constant time step' % self.__name__
            return False
        else:
            return True

    def advance(self):
        u, f, n, t = self.u, self.f, self.n, self.t

        if n &gt;= 1:
            dt = t[n+1] - t[n]  # must be constant
            self.f_n = f(u[n], t[n])
            unew = u[n] + dt/2.*(3*self.f_n - self.f_n_1)
            self.f_n_1 = self.f_n
        else:
            # User-specified method for the first step
            self.starter.set_initial_condition(u[n])
            time_points = [t[n], t[n+1]]
            u_starter, t_starter = self.starter.solve(time_points)
            unew = u_starter[-1]
            self.f_n_1 = f(u[0], t[0])

        return unew
</code></pre>
<!-- end verbatim block -->
Three features are worth comments: 1) we extend the set of optional
parameters; 2) we must initialize a separate solver for the first
step, and this is done in the <code>initialize_for_solve</code> method that will
be called as part of <code>solve</code> before the time stepping; and 3) we
extend <code>validate_data</code> to check that the time spacing given by the
<code>time_points</code> argument to <code>solve</code> is constant. The utility method
<code>constant_time_step</code> provided in super class <code>Solver</code> carries out the
details of the check.

<p>
More advanced implementations of subclasses can be studied
in the <a href="https://github.com/hplgit/odespy/tree/master/odespy/odespy/solvers.py" target="_self"><tt>solvers.py</tt></a> and <a href="https://github.com/hplgit/odespy/tree/master/odespy/odespy/RungeKutta.py" target="_self"><tt>RungeKutta.py</tt></a> files.

<h2 id="___sec55">A Simple Example of an Implicit Method </h2>

<p>
Class <code>SolverImplicit</code> acts as superclass for the implementation of
implicit methods. This class provides some basic functionality for
solving the system of nonlinear equations that normally arises in
implicit methods by Picard or Newton iteration.
The parameter <code>nonlinear_solver</code> can take the values <code>Picard</code> or
<code>Newton</code>. The user must in case of Newton's method provide
a <code>jac</code> parameter for a function evaluating the Jacobian of \( f(u,t) \)
with respect to \( u \): \( J_{i,j} = \partial f_i/\partial u_j \).

<p>
Instead of implementing an <code>advance</code> method in subclasses, one provides
a method <code>Picard</code> and/or <code>Newton</code> to define key quantities in these
methods. The superclass implements <code>advance</code>, which will run a Picard
or Newton iteration. The <code>Picard</code> method returns all the terms
on the right-hand side of the discrete equation when only <code>u[n+1]</code> is
on the left-hand side. <code>Newton</code> returns the right-hand side and the
Jacobian of the system to be solved in each Newton iteration.

<p>
Here is an example showing the complete code of the Backward Euler method.
<!-- begin verbatim block  pycod-->
<pre><code>class BackwardEuler(SolverImplicit):
    &quot;&quot;&quot;
    Implicit Backward Euler method::

       u[n+1] = u[n] + dt*f(t[n+1], u[n+1])

    The nonlinear system is solved by Newton or Picard iteration.
    &quot;&quot;&quot;
    quick_description = &quot;Implicit 1st-order Backward Euler method&quot;

    def Picard_update(self, ukp1):
        u, f, n, t = self.u, self.f, self.n, self.t
        dt = t[n+1] - t[n]
        return u[n] + dt*f(ukp1, t[n+1])

    def Newton_system(self, ukp1):
        u, f, n, t = self.u, self.f, self.n, self.t
        dt = t[n+1] - t[n]
        F = ukp1 - (u[n] + dt*f(ukp1, t[n+1]))
        J = np.eye(self.neq) - dt*self.jac(ukp1, t[n+1])
        return F, J
</code></pre>
<!-- end verbatim block -->

<h1 id="___sec56">Troubleshooting </h1>

<h2 id="___sec57">Constructor takes exactly two arguments, 5 given </h2>

<p>
Constructors in the <code>Solver</code> hierarchy take only the <code>f</code> function
as positional argument. All other parameters to the constructor
must be keyword arguments.

<p>
<b>Remark.</b>
This document was written with aid of the
<a href="https://github.com/hplgit/doconce" target="_self">DocOnce</a> tool, which allows
output in many different formats.

<!-- ------------------- end of main content --------------- -->


</body>
</html>
    

